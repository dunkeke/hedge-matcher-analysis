import streamlit as st
import pandas as pd
import numpy as np
import io
import time
import warnings
from datetime import datetime, timedelta
from collections import deque
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots  # æ·»åŠ è¿™è¡Œ
import re
import json

warnings.filterwarnings("ignore", category=UserWarning)

# ---------------------------------------------------------
# 1. æ ¸å¿ƒåŒ¹é…å¼•æ“ (å®Œæ•´é›†æˆ)
# ---------------------------------------------------------

class HedgeMatchingEngine:
    """å¥—ä¿åŒ¹é…å¼•æ“ - å®Œæ•´ç‰ˆ"""
    
    def __init__(self):
        self.df_paper = None
        self.df_physical = None
        self.df_paper_net = None
        self.df_relations = None
        self.df_physical_updated = None
        
    def clean_str(self, series):
        """æ¸…æ´—å­—ç¬¦ä¸²"""
        return series.astype(str).str.strip().str.upper().replace('NAN', '')
    
    def standardize_month(self, series):
        """æ ‡å‡†åŒ–æœˆä»½æ ¼å¼"""
        s = series.astype(str).str.strip().str.upper()
        s = s.str.replace('-', ' ', regex=False).str.replace('/', ' ', regex=False)
        dates = pd.to_datetime(s, errors='coerce')
        result = dates.dt.strftime('%b %y').str.upper()
        mask_invalid = dates.isna()
        
        if mask_invalid.any():
            invalid = s[mask_invalid]
            def swap_if_match(val):
                m = re.match(r'^(\d{2})\s*([A-Z]{3})$', val)
                if m:
                    yr, mon = m.groups()
                    return f"{mon} {yr}"
                return val
            swapped = invalid.map(swap_if_match)
            swapped_dates = pd.to_datetime(swapped, errors='coerce')
            swapped_formatted = swapped_dates.dt.strftime('%b %y').str.upper()
            result.loc[mask_invalid & swapped_dates.notna()] = swapped_formatted.loc[swapped_dates.notna()]
            result.loc[mask_invalid & swapped_dates.isna()] = swapped.loc[swapped_dates.isna()]
        return result
    
    def calculate_net_positions(self, df_paper):
        """FIFOå‡€ä»“è®¡ç®—"""
        st.info("ğŸ”„ æ‰§è¡Œçº¸è´§å†…éƒ¨å¯¹å†² (FIFO Netting)...")
        progress_bar = st.progress(0)
        
        df_paper = df_paper.sort_values(by='Trade Date').reset_index(drop=True)
        df_paper['Group_Key'] = df_paper['Std_Commodity'] + "_" + df_paper['Month']
        records = df_paper.to_dict('records')
        groups = {}
        
        # åˆ†ç»„
        for i, row in enumerate(records):
            key = row['Group_Key']
            if key not in groups:
                groups[key] = []
            groups[key].append(i)
            if i % 100 == 0:
                progress_bar.progress(min(i / len(records) * 0.5, 0.5))
        
        # FIFOå‡€é¢åŒ–
        group_count = 0
        total_groups = len(groups)
        for key, indices in groups.items():
            open_queue = deque()
            for idx in indices:
                row = records[idx]
                current_vol = row.get('Volume', 0)
                records[idx]['Net_Open_Vol'] = current_vol
                records[idx]['Closed_Vol'] = 0
                records[idx]['Close_Events'] = []
                
                if abs(current_vol) < 0.0001:
                    continue
                
                current_sign = 1 if current_vol > 0 else -1
                
                # å°è¯•ä¸é˜Ÿåˆ—ä¸­çš„äº¤æ˜“æŠµæ¶ˆ
                while open_queue:
                    q_idx, q_vol, q_sign = open_queue[0]
                    if q_sign != current_sign:  # æ–¹å‘ç›¸åæ‰èƒ½æŠµæ¶ˆ
                        offset = min(abs(current_vol), abs(q_vol))
                        current_vol -= (current_sign * offset)
                        q_vol -= (q_sign * offset)
                        
                        # è®°å½•å¹³ä»“äº‹ä»¶
                        close_event = {
                            'Ref': str(records[idx].get('Recap No', '')),
                            'Date': records[idx].get('Trade Date'),
                            'Vol': offset,
                            'Price': records[idx].get('Price', 0)
                        }
                        records[q_idx]['Close_Events'].append(close_event)
                        records[q_idx]['Closed_Vol'] += offset
                        records[q_idx]['Net_Open_Vol'] = q_vol
                        records[idx]['Closed_Vol'] += offset
                        records[idx]['Net_Open_Vol'] = current_vol
                        
                        if abs(q_vol) < 0.0001:
                            open_queue.popleft()
                        else:
                            open_queue[0] = (q_idx, q_vol, q_sign)
                        
                        if abs(current_vol) < 0.0001:
                            break
                    else:
                        break
                
                # å‰©ä½™éƒ¨åˆ†å…¥é˜Ÿ
                if abs(current_vol) > 0.0001:
                    open_queue.append((idx, current_vol, current_sign))
            
            group_count += 1
            progress_bar.progress(0.5 + (group_count / total_groups) * 0.5)
        
        progress_bar.progress(1.0)
        st.success(f"âœ… çº¸è´§å†…éƒ¨å¯¹å†²å®Œæˆï¼å…±å¤„ç† {len(groups)} ä¸ªå•†å“-æœˆä»½ç»„åˆ")
        return pd.DataFrame(records)
    
    def match_hedges(self, df_physical, df_paper_net):
        """å®è´§åŒ¹é…"""
        st.info("ğŸ”„ å¼€å§‹å®è´§åŒ¹é…...")
        progress_bar = st.progress(0)
        
        hedge_relations = []
        active_paper = df_paper_net.copy()
        active_paper['Allocated_To_Phy'] = 0.0
        active_paper['_original_index'] = active_paper.index
        
        df_phy = df_physical.copy()
        df_phy['_orig_idx'] = df_phy.index
        
        # BRENTä¼˜å…ˆåŒ¹é…
        if 'Pricing_Benchmark' in df_phy.columns:
            def bench_prio(x):
                x_str = str(x).upper()
                return 0 if 'BRENT' in x_str else 1
            df_phy['_priority'] = df_phy['Pricing_Benchmark'].apply(bench_prio)
            df_phy = df_phy.sort_values(by=['_priority', '_orig_idx']).reset_index(drop=True)
            df_phy = df_phy.drop(columns=['_priority'])
        else:
            df_phy = df_phy.reset_index(drop=True)
        
        total_cargos = len(df_phy)
        
        for idx, (_, cargo) in enumerate(df_phy.iterrows()):
            cargo_id = cargo.get('Cargo_ID')
            phy_vol = cargo.get('Unhedged_Volume', 0)
            
            if abs(phy_vol) < 0.0001:
                continue
            
            proxy = str(cargo.get('Hedge_Proxy', ''))
            target_month = cargo.get('Target_Contract_Month', None)
            phy_dir = cargo.get('Direction', 'Buy')
            desig_date = cargo.get('Designation_Date', pd.NaT)
            
            # ç­›é€‰å€™é€‰äº¤æ˜“
            candidates_df = active_paper[
                (active_paper['Std_Commodity'].str.contains(proxy, regex=False)) &
                (active_paper['Month'] == target_month)
            ].copy()
            
            if candidates_df.empty:
                continue
            
            # æ—¶é—´æ’åºï¼šæœ‰æŒ‡å®šæ—¥æœŸæŒ‰æ—¶é—´å·®ï¼Œå¦åˆ™FIFO
            if pd.notna(desig_date) and not candidates_df['Trade Date'].isnull().all():
                candidates_df['Time_Lag_Days'] = (candidates_df['Trade Date'] - desig_date).dt.days
                candidates_df['Abs_Lag'] = candidates_df['Time_Lag_Days'].abs()
                candidates_df = candidates_df.sort_values(by=['Abs_Lag', 'Trade Date'])
            else:
                candidates_df['Time_Lag_Days'] = np.nan
                candidates_df = candidates_df.sort_values(by='Trade Date')
            
            # åˆ†é…åŒ¹é…
            for _, ticket in candidates_df.iterrows():
                if abs(phy_vol) < 1:
                    break
                
                original_index = ticket['_original_index']
                curr_allocated = active_paper.at[original_index, 'Allocated_To_Phy']
                curr_total_vol = ticket.get('Volume', 0)
                avail = curr_total_vol - curr_allocated
                
                if abs(avail) < 0.0001:
                    continue
                
                alloc_amt_abs = abs(phy_vol) if abs(avail) >= abs(phy_vol) else abs(avail)
                alloc_amt = np.sign(avail) * alloc_amt_abs
                phy_vol -= alloc_amt_abs
                active_paper.at[original_index, 'Allocated_To_Phy'] += alloc_amt
                
                # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
                open_price = ticket.get('Price', 0)
                mtm_price = ticket.get('Mtm Price', open_price)  # é»˜è®¤ä¸ºå¼€ä»“ä»·
                total_pl_raw = ticket.get('Total P/L', 0)
                close_events = ticket.get('Close_Events', [])
                
                # æ ¼å¼åŒ–å¹³ä»“è·¯å¾„
                close_path_str = ""
                if close_events:
                    try:
                        sorted_events = sorted(close_events, key=lambda x: x['Date'] if pd.notna(x['Date']) else pd.Timestamp.min)
                        details = []
                        for e in sorted_events:
                            d_str = e['Date'].strftime('%Y-%m-%d') if pd.notna(e['Date']) else 'N/A'
                            p_str = f"@{e['Price']}" if pd.notna(e['Price']) else ""
                            details.append(f"[{d_str} Tkt#{e['Ref']} Vol:{e['Vol']:.0f} {p_str}]")
                        close_path_str = " -> ".join(details)
                    except:
                        close_path_str = str(close_events)
                
                # è®¡ç®—åˆ†é…æ¯”ä¾‹
                ratio = abs(alloc_amt) / abs(curr_total_vol) if abs(curr_total_vol) > 0 else 0
                unrealized_mtm = (mtm_price - open_price) * alloc_amt
                allocated_total_pl = total_pl_raw * ratio
                
                hedge_relations.append({
                    'Cargo_ID': cargo_id,
                    'Proxy': proxy,
                    'Designation_Date': desig_date,
                    'Open_Date': ticket.get('Trade Date'),
                    'Time_Lag': ticket.get('Time_Lag_Days'),
                    'Ticket_ID': ticket.get('Recap No'),
                    'Month': ticket.get('Month'),
                    'Allocated_Vol': alloc_amt,
                    'Trade_Volume': ticket.get('Volume', 0),
                    'Trade_Net_Open': ticket.get('Net_Open_Vol', 0),
                    'Trade_Closed_Vol': ticket.get('Closed_Vol', 0),
                    'Open_Price': open_price,
                    'MTM_Price': mtm_price,
                    'Alloc_Unrealized_MTM': round(unrealized_mtm, 2),
                    'Alloc_Total_PL': round(allocated_total_pl, 2),
                    'Close_Path_Details': close_path_str,
                })
                
                # æ›´æ–°å®è´§æœªå¯¹å†²é‡
                orig_idx = cargo.get('_orig_idx')
                if orig_idx in df_physical.index:
                    df_physical.at[orig_idx, 'Unhedged_Volume'] = phy_vol
            
            progress_bar.progress((idx + 1) / total_cargos)
        
        # æ›´æ–°åˆ†é…é‡
        cols_to_update = active_paper[['_original_index', 'Allocated_To_Phy']].set_index('_original_index')
        df_paper_net.update(cols_to_update)
        
        progress_bar.progress(1.0)
        df_relations = pd.DataFrame(hedge_relations)
        st.success(f"âœ… å®è´§åŒ¹é…å®Œæˆï¼å…±ç”Ÿæˆ {len(df_relations)} æ¡åŒ¹é…è®°å½•")
        
        return df_relations, df_physical
    
    def run_matching(self, df_paper_raw, df_physical_raw):
        """æ‰§è¡Œå®Œæ•´åŒ¹é…æµç¨‹"""
        # æ•°æ®é¢„å¤„ç†
        st.info("ğŸ”„ æ•°æ®é¢„å¤„ç†ä¸­...")
        
        # çº¸è´§é¢„å¤„ç†
        df_paper = df_paper_raw.copy()
        
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        required_cols_paper = ['Trade Date', 'Volume', 'Commodity']
        for col in required_cols_paper:
            if col not in df_paper.columns:
                st.error(f"çº¸è´§æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {col}")
                return None, None, None, None
        
        # æ ‡å‡†åŒ–å¤„ç†
        df_paper['Trade Date'] = pd.to_datetime(df_paper['Trade Date'], errors='coerce')
        df_paper['Volume'] = pd.to_numeric(df_paper['Volume'], errors='coerce').fillna(0)
        df_paper['Std_Commodity'] = self.clean_str(df_paper['Commodity'])
        
        if 'Month' in df_paper.columns:
            df_paper['Month'] = self.standardize_month(df_paper['Month'])
        else:
            # å¦‚æœæ²¡æœ‰Monthåˆ—ï¼Œå°è¯•ä»å…¶ä»–åˆ—æ¨æ–­æˆ–åˆ›å»ºé»˜è®¤å€¼
            df_paper['Month'] = df_paper['Trade Date'].dt.strftime('%b %y').str.upper()
        
        # å¤„ç†ç¼ºå¤±å­—æ®µ
        if 'Recap No' not in df_paper.columns:
            df_paper['Recap No'] = [f"TKT-{i+1:04d}" for i in range(len(df_paper))]
        
        for col in ['Price', 'Mtm Price', 'Total P/L']:
            if col not in df_paper.columns:
                df_paper[col] = 0.0
        
        # å®è´§é¢„å¤„ç†
        df_physical = df_physical_raw.copy()
        
        # æ ‡å‡†åŒ–åˆ—å
        col_mapping = {
            'Target_Pricing_Month': 'Target_Contract_Month',
            'Month': 'Target_Contract_Month',
            'Hedge_Proxy': 'Hedge_Proxy',
            'Direction': 'Direction'
        }
        
        for old_col, new_col in col_mapping.items():
            if old_col in df_physical.columns and new_col not in df_physical.columns:
                df_physical[new_col] = df_physical[old_col]
        
        # ç¡®ä¿å¿…è¦åˆ—
        if 'Volume' in df_physical.columns:
            df_physical['Volume'] = pd.to_numeric(df_physical['Volume'], errors='coerce').fillna(0)
            df_physical['Unhedged_Volume'] = df_physical['Volume']
        
        if 'Hedge_Proxy' in df_physical.columns:
            df_physical['Hedge_Proxy'] = self.clean_str(df_physical['Hedge_Proxy'])
        
        if 'Target_Contract_Month' in df_physical.columns:
            df_physical['Target_Contract_Month'] = self.standardize_month(df_physical['Target_Contract_Month'])
        
        # æŒ‡å®šæ—¥æœŸ
        date_cols = ['Designation_Date', 'Pricing_Start', 'Trade Date']
        for col in date_cols:
            if col in df_physical.columns:
                df_physical['Designation_Date'] = pd.to_datetime(df_physical[col], errors='coerce')
                break
        else:
            df_physical['Designation_Date'] = pd.NaT
        
        # æ‰§è¡ŒåŒ¹é…
        self.df_paper_net = self.calculate_net_positions(df_paper)
        self.df_relations, self.df_physical_updated = self.match_hedges(df_physical, self.df_paper_net)
        
        return self.df_relations, self.df_physical_updated, self.df_paper_net, df_paper

# ---------------------------------------------------------
# 2. åˆ†ææ¨¡å— (åŸºäºçœŸå®åŒ¹é…ç»“æœ)
# ---------------------------------------------------------

class HedgeAnalysis:
    """å¥—ä¿åˆ†ææ¨¡å—"""
    
    def __init__(self, df_relations, df_physical, df_paper_net):
        self.df_relations = df_relations
        self.df_physical = df_physical
        self.df_paper_net = df_paper_net
        self.summary_stats = {}
        self.calculate_summary()
    
    def calculate_summary(self):
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        if self.df_relations.empty:
            return
        
        try:
            # åŒ¹é…ç»Ÿè®¡
            total_matched = abs(self.df_relations['Allocated_Vol']).sum() if 'Allocated_Vol' in self.df_relations.columns else 0
            total_physical = abs(self.df_physical['Volume']).sum() if 'Volume' in self.df_physical.columns else 0
            match_rate = (total_matched / total_physical * 100) if total_physical > 0 else 0
            
            # è´¢åŠ¡ç»Ÿè®¡
            total_pl = self.df_relations['Alloc_Total_PL'].sum() if 'Alloc_Total_PL' in self.df_relations.columns else 0
            total_unrealized = self.df_relations['Alloc_Unrealized_MTM'].sum() if 'Alloc_Unrealized_MTM' in self.df_relations.columns else 0
            
            # æ•°é‡ç»Ÿè®¡
            matched_cargos = self.df_relations['Cargo_ID'].nunique() if 'Cargo_ID' in self.df_relations.columns else 0
            total_cargos = self.df_physical['Cargo_ID'].nunique() if 'Cargo_ID' in self.df_physical.columns else 0
            total_tickets = len(self.df_relations)
            
            # æ—¶é—´ç»Ÿè®¡
            if 'Time_Lag' in self.df_relations.columns:
                time_lag_abs = self.df_relations['Time_Lag'].abs()
                avg_time_lag = time_lag_abs.mean() if not time_lag_abs.isna().all() else 0
                std_time_lag = time_lag_abs.std() if not time_lag_abs.isna().all() else 0
            else:
                avg_time_lag = std_time_lag = 0
            
            self.summary_stats = {
                'total_matched': total_matched,
                'total_physical': total_physical,
                'match_rate': match_rate,
                'total_pl': total_pl,
                'total_unrealized': total_unrealized,
                'matched_cargos': matched_cargos,
                'total_cargos': total_cargos,
                'total_tickets': total_tickets,
                'avg_time_lag': avg_time_lag,
                'std_time_lag': std_time_lag
            }
        except Exception as e:
            st.warning(f"è®¡ç®—æ±‡æ€»ç»Ÿè®¡æ—¶å‡ºé”™: {e}")
            self.summary_stats = {
                'total_matched': 0,
                'total_physical': 0,
                'match_rate': 0,
                'total_pl': 0,
                'total_unrealized': 0,
                'matched_cargos': 0,
                'total_cargos': 0,
                'total_tickets': 0,
                'avg_time_lag': 0,
                'std_time_lag': 0
            }
    
    def create_summary_metrics(self):
        """åˆ›å»ºæ¦‚è§ˆæŒ‡æ ‡å¡ç‰‡"""
        stats = self.summary_stats
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“Š åŒ¹é…ç‡", f"{stats['match_rate']:.1f}%", 
                     delta=f"{stats['total_matched']:,.0f}/{stats['total_physical']:,.0f}")
        
        with col2:
            coverage = (stats['matched_cargos'] / stats['total_cargos'] * 100) if stats['total_cargos'] > 0 else 0
            st.metric("ğŸ“¦ åŒ¹é…è¦†ç›–ç‡", f"{coverage:.1f}%",
                     delta=f"{stats['matched_cargos']}/{stats['total_cargos']}")
        
        with col3:
            st.metric("ğŸ’° æ€»P/L", f"${stats['total_pl']:,.2f}",
                     delta=f"æœªå®ç°: ${stats['total_unrealized']:,.2f}")
        
        with col4:
            st.metric("â±ï¸ å¹³å‡æ—¶é—´å·®", f"{stats['avg_time_lag']:.1f}å¤©",
                     delta=f"Â±{stats['std_time_lag']:.1f}å¤©")
    
    def create_match_volume_chart(self):
        """åŒ¹é…é‡åˆ†å¸ƒå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Allocated_Vol' not in self.df_relations.columns:
                return None
            
            # æŒ‰Cargo_IDæ±‡æ€»
            cargo_summary = self.df_relations.copy()
            cargo_summary['Allocated_Vol_Abs'] = abs(cargo_summary['Allocated_Vol'])
            
            if 'Cargo_ID' not in cargo_summary.columns:
                return None
            
            cargo_group = cargo_summary.groupby('Cargo_ID')['Allocated_Vol_Abs'].sum().reset_index()
            
            # æŒ‰åŒ¹é…é‡æ’åºï¼Œå–å‰20
            top_cargos = cargo_group.sort_values('Allocated_Vol_Abs', ascending=False).head(20)
            
            fig = px.bar(top_cargos, 
                         x='Cargo_ID', y='Allocated_Vol_Abs',
                         title='ğŸ“ˆ å„Cargo_IDåŒ¹é…é‡TOP20',
                         labels={'Allocated_Vol_Abs': 'åŒ¹é…é‡', 'Cargo_ID': 'å®è´§ç¼–å·'},
                         color='Allocated_Vol_Abs',
                         color_continuous_scale='Viridis')
            fig.update_layout(xaxis_tickangle=-45)
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºåŒ¹é…é‡å›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_pl_analysis_chart(self):
        """P/Låˆ†æå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Alloc_Total_PL' not in self.df_relations.columns:
                return None
            
            # ä½¿ç”¨æ›´ç®€å•çš„å›¾è¡¨ï¼Œé¿å…å¤æ‚å­å›¾
            fig = px.histogram(self.df_relations, 
                              x='Alloc_Total_PL',
                              nbins=30,
                              title='ğŸ’° P/Låˆ†å¸ƒç›´æ–¹å›¾',
                              labels={'Alloc_Total_PL': 'P/Lå€¼'})
            fig.add_vline(x=0, line_dash="dash", line_color="red")
            
            # æ·»åŠ ç®±çº¿å›¾æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            fig2 = px.box(self.df_relations, 
                         y='Alloc_Total_PL',
                         title='ğŸ“Š P/Lç»Ÿè®¡ç®±çº¿å›¾')
            
            return fig, fig2
        except Exception as e:
            st.warning(f"åˆ›å»ºP/Lå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None, None
    
    def create_simple_pl_chart(self):
        """ç®€åŒ–çš„P/Lå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Alloc_Total_PL' not in self.df_relations.columns:
                return None
            
            fig = go.Figure()
            
            # æ·»åŠ ç›´æ–¹å›¾
            fig.add_trace(go.Histogram(
                x=self.df_relations['Alloc_Total_PL'],
                nbinsx=30,
                name='P/Låˆ†å¸ƒ',
                marker_color='skyblue'
            ))
            
            # æ·»åŠ é›¶çº¿
            fig.add_vline(x=0, line_dash="dash", line_color="red")
            
            fig.update_layout(
                title='ğŸ’° P/Låˆ†å¸ƒåˆ†æ',
                xaxis_title='P/Lå€¼',
                yaxis_title='é¢‘æ•°',
                showlegend=False
            )
            
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºç®€åŒ–P/Lå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_time_analysis_chart(self):
        """æ—¶é—´åˆ†æå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Time_Lag' not in self.df_relations.columns:
                return None
            
            time_lag_data = self.df_relations['Time_Lag'].dropna()
            if time_lag_data.empty:
                return None
            
            fig = px.histogram(time_lag_data,
                             nbinsx=30,
                             title='â±ï¸ æ—¶é—´å·®åˆ†å¸ƒ',
                             labels={'value': 'æ—¶é—´å·®(å¤©)'})
            fig.add_vline(x=0, line_dash="dash", line_color="green",
                         annotation_text="å®Œç¾åŒ¹é…")
            
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºæ—¶é—´åˆ†æå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_price_analysis_chart(self):
        """ä»·æ ¼åˆ†æå›¾è¡¨"""
        try:
            if self.df_relations.empty:
                return None
            
            required_cols = ['Open_Price', 'MTM_Price', 'Allocated_Vol']
            missing_cols = [col for col in required_cols if col not in self.df_relations.columns]
            
            if missing_cols:
                st.info(f"ç¼ºå°‘ä»·æ ¼åˆ†ææ‰€éœ€åˆ—: {missing_cols}")
                return None
            
            fig = px.scatter(self.df_relations, 
                            x='Open_Price', 
                            y='MTM_Price',
                            size=abs(self.df_relations['Allocated_Vol']),
                            color='Alloc_Total_PL' if 'Alloc_Total_PL' in self.df_relations.columns else None,
                            title='ğŸ’¹ å¼€ä»“ä»· vs å½“å‰ä»·åˆ†æ',
                            labels={'Open_Price': 'å¼€ä»“ä»·', 'MTM_Price': 'å½“å‰ä»·'},
                            hover_data=['Cargo_ID', 'Ticket_ID', 'Allocated_Vol'] if 'Cargo_ID' in self.df_relations.columns else [])
            
            # æ·»åŠ å¹³ä»·çº¿
            min_price = min(self.df_relations['Open_Price'].min(), self.df_relations['MTM_Price'].min())
            max_price = max(self.df_relations['Open_Price'].max(), self.df_relations['MTM_Price'].max())
            
            fig.add_trace(go.Scatter(x=[min_price, max_price],
                                    y=[min_price, max_price],
                                    mode='lines',
                                    name='å¹³ä»·çº¿',
                                    line=dict(color='red', dash='dash')))
            
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºä»·æ ¼åˆ†æå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_month_distribution_chart(self):
        """æœˆä»½åˆ†å¸ƒå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Month' not in self.df_relations.columns:
                return None
            
            month_summary = self.df_relations.copy()
            month_summary['Allocated_Vol_Abs'] = abs(month_summary['Allocated_Vol'])
            month_group = month_summary.groupby('Month')['Allocated_Vol_Abs'].sum().reset_index()
            
            fig = px.bar(month_group.sort_values('Allocated_Vol_Abs', ascending=False),
                         x='Month', y='Allocated_Vol_Abs',
                         title='ğŸ“… å„æœˆä»½åŒ¹é…é‡åˆ†å¸ƒ',
                         labels={'Allocated_Vol_Abs': 'åŒ¹é…é‡', 'Month': 'åˆçº¦æœˆä»½'},
                         color='Allocated_Vol_Abs',
                         color_continuous_scale='Plasma')
            fig.update_layout(xaxis_tickangle=-45)
            
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºæœˆä»½åˆ†å¸ƒå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_match_detail_table(self, max_rows=50):
        """åˆ›å»ºåŒ¹é…æ˜ç»†è¡¨"""
        try:
            if self.df_relations.empty:
                return pd.DataFrame()
            
            # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
            display_cols = []
            possible_cols = ['Cargo_ID', 'Ticket_ID', 'Month', 'Allocated_Vol',
                            'Open_Price', 'MTM_Price', 'Alloc_Total_PL',
                            'Alloc_Unrealized_MTM', 'Time_Lag', 'Proxy']
            
            for col in possible_cols:
                if col in self.df_relations.columns:
                    display_cols.append(col)
            
            if not display_cols:
                return pd.DataFrame()
            
            # æ ¼å¼åŒ–æ•°å­—
            formatted_df = self.df_relations[display_cols].copy()
            
            # æ•°å­—æ ¼å¼åŒ–å‡½æ•°
            def format_number(x):
                if isinstance(x, (int, float, np.integer, np.floating)):
                    return f"{x:,.2f}"
                return x
            
            # æ ¼å¼åŒ–æ•°å€¼åˆ—
            num_cols = ['Allocated_Vol', 'Open_Price', 'MTM_Price', 
                       'Alloc_Total_PL', 'Alloc_Unrealized_MTM']
            for col in num_cols:
                if col in formatted_df.columns:
                    formatted_df[col] = formatted_df[col].apply(format_number)
            
            return formatted_df.head(max_rows)
        except Exception as e:
            st.warning(f"åˆ›å»ºåŒ¹é…æ˜ç»†è¡¨æ—¶å‡ºé”™: {e}")
            return pd.DataFrame()
    
    def create_risk_metrics(self):
        """é£é™©æŒ‡æ ‡è®¡ç®—"""
        try:
            if self.df_relations.empty or 'Alloc_Total_PL' not in self.df_relations.columns:
                return {}
            
            risk_metrics = {}
            pl_series = self.df_relations['Alloc_Total_PL']
            
            # VaRè®¡ç®— (95%ç½®ä¿¡æ°´å¹³)
            if len(pl_series) > 1:
                var_95 = np.percentile(pl_series, 5)  # 95% VaR
                cvar_95 = pl_series[pl_series <= var_95].mean() if len(pl_series[pl_series <= var_95]) > 0 else 0
                risk_metrics['VaR_95'] = var_95
                risk_metrics['CVaR_95'] = cvar_95
                risk_metrics['PL_StdDev'] = pl_series.std()
                risk_metrics['PL_Max'] = pl_series.max()
                risk_metrics['PL_Min'] = pl_series.min()
                
                # å¤æ™®æ¯”ç‡ (å‡è®¾æ— é£é™©åˆ©ç‡ä¸º0)
                avg_pl = pl_series.mean()
                std_pl = pl_series.std()
                risk_metrics['Sharpe_Ratio'] = avg_pl / std_pl if std_pl != 0 else 0
                
                # æœ€å¤§å›æ’¤
                pl_cumulative = pl_series.cumsum()
                running_max = pl_cumulative.expanding().max()
                drawdown = (pl_cumulative - running_max) / running_max * 100
                risk_metrics['Max_Drawdown'] = drawdown.min() if not drawdown.empty else 0
            
            return risk_metrics
        except Exception as e:
            st.warning(f"è®¡ç®—é£é™©æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            return {}

# ---------------------------------------------------------
# 3. Streamlit ä¸»åº”ç”¨
# ---------------------------------------------------------

def main():
    st.set_page_config(
        page_title="å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #374151;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        border-bottom: 2px solid #E5E7EB;
        padding-bottom: 0.5rem;
    }
    .success-box {
        background-color: #D1FAE5;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #10B981;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #DBEAFE;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3B82F6;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #FEF3C7;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #F59E0B;
        margin: 1rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ“ˆ å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    st.markdown("### ä¸“ä¸šå¥—ä¿åŒ¹é…ä¸é£é™©åˆ†æå·¥å…· | åŸºäºçœŸå®åŒ¹é…æ•°æ®")
    
    # åˆå§‹åŒ–session state
    if 'engine' not in st.session_state:
        st.session_state.engine = HedgeMatchingEngine()
    if 'analysis' not in st.session_state:
        st.session_state.analysis = None
    if 'matching_complete' not in st.session_state:
        st.session_state.matching_complete = False
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.markdown("### ğŸ“ æ•°æ®ä¸Šä¼ ")
        
        paper_file = st.file_uploader(
            "çº¸è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="paper_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Trade Date, Volume, Commodityç­‰å­—æ®µ"
        )
        
        physical_file = st.file_uploader(
            "å®è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="physical_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Cargo_ID, Volume, Hedge_Proxyç­‰å­—æ®µ"
        )
        
        st.markdown("---")
        st.markdown("### âš™ï¸ åˆ†æè®¾ç½®")
        
        show_charts = st.checkbox("æ˜¾ç¤ºåˆ†æå›¾è¡¨", value=True)
        show_risk = st.checkbox("æ˜¾ç¤ºé£é™©æŒ‡æ ‡", value=True)
        max_rows = st.slider("è¡¨æ ¼æ˜¾ç¤ºè¡Œæ•°", 10, 200, 50)
        
        st.markdown("---")
        
        if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰æ•°æ®", type="secondary"):
            st.session_state.engine = HedgeMatchingEngine()
            st.session_state.analysis = None
            st.session_state.matching_complete = False
            st.rerun()
    
    # ä¸»å†…å®¹åŒº
    if paper_file is not None and physical_file is not None:
        # è¯»å–æ•°æ®
        try:
            # è¯»å–çº¸è´§æ•°æ®
            if paper_file.name.endswith(('.xlsx', '.xls')):
                df_paper_raw = pd.read_excel(paper_file)
            else:
                df_paper_raw = pd.read_csv(paper_file)
            
            # è¯»å–å®è´§æ•°æ®
            if physical_file.name.endswith(('.xlsx', '.xls')):
                df_physical_raw = pd.read_excel(physical_file)
            else:
                df_physical_raw = pd.read_csv(physical_file)
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            with st.expander("ğŸ“‹ åŸå§‹æ•°æ®é¢„è§ˆ", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**çº¸è´§æ•°æ®** ({len(df_paper_raw)}è¡Œ, {len(df_paper_raw.columns)}åˆ—)")
                    st.dataframe(df_paper_raw.head(10), use_container_width=True)
                    st.caption(f"å­—æ®µ: {', '.join(df_paper_raw.columns.tolist()[:8])}...")
                
                with col2:
                    st.markdown(f"**å®è´§æ•°æ®** ({len(df_physical_raw)}è¡Œ, {len(df_physical_raw.columns)}åˆ—)")
                    st.dataframe(df_physical_raw.head(10), use_container_width=True)
                    st.caption(f"å­—æ®µ: {', '.join(df_physical_raw.columns.tolist()[:8])}...")
            
            # æ‰§è¡ŒåŒ¹é…æŒ‰é’®
            if st.button("ğŸš€ æ‰§è¡Œå¥—ä¿åŒ¹é…", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨æ‰§è¡Œå¥—ä¿åŒ¹é…ï¼Œè¯·ç¨å€™..."):
                    try:
                        # æ‰§è¡ŒåŒ¹é…
                        df_relations, df_physical_updated, df_paper_net, df_paper_processed = st.session_state.engine.run_matching(
                            df_paper_raw, df_physical_raw
                        )
                        
                        if df_relations is not None and not df_relations.empty:
                            # åˆ›å»ºåˆ†ææ¨¡å—
                            st.session_state.analysis = HedgeAnalysis(
                                df_relations, df_physical_updated, df_paper_net
                            )
                            st.session_state.matching_complete = True
                            
                            # æ˜¾ç¤ºåŒ¹é…æˆåŠŸä¿¡æ¯
                            st.markdown('<div class="success-box">âœ… å¥—ä¿åŒ¹é…æˆåŠŸå®Œæˆï¼</div>', unsafe_allow_html=True)
                            
                            # æ˜¾ç¤ºåŒ¹é…è¿‡ç¨‹æ•°æ®
                            with st.expander("ğŸ“Š åŒ¹é…è¿‡ç¨‹æ•°æ®", expanded=False):
                                tab1, tab2, tab3 = st.tabs(["çº¸è´§å‡€ä»“", "å®è´§æ›´æ–°", "åŒ¹é…å…³ç³»"])
                                
                                with tab1:
                                    if df_paper_net is not None:
                                        st.dataframe(df_paper_net.head(20), use_container_width=True)
                                        st.caption(f"çº¸è´§å‡€ä»“æ•°æ® ({len(df_paper_net)}è¡Œ)")
                                    else:
                                        st.info("æ— çº¸è´§å‡€ä»“æ•°æ®")
                                
                                with tab2:
                                    if df_physical_updated is not None:
                                        st.dataframe(df_physical_updated.head(20), use_container_width=True)
                                        st.caption(f"æ›´æ–°åå®è´§æ•°æ® ({len(df_physical_updated)}è¡Œ)")
                                    else:
                                        st.info("æ— å®è´§æ›´æ–°æ•°æ®")
                                
                                with tab3:
                                    if df_relations is not None:
                                        st.dataframe(df_relations.head(20), use_container_width=True)
                                        st.caption(f"åŒ¹é…å…³ç³»æ•°æ® ({len(df_relations)}è¡Œ)")
                                    else:
                                        st.info("æ— åŒ¹é…å…³ç³»æ•°æ®")
                        else:
                            st.markdown('<div class="warning-box">âš ï¸ åŒ¹é…å®Œæˆä½†æœªç”ŸæˆåŒ¹é…è®°å½•ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼å’Œå†…å®¹</div>', unsafe_allow_html=True)
                            
                    except Exception as e:
                        st.error(f"åŒ¹é…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                        st.exception(e)
        
        except Exception as e:
            st.error(f"æ•°æ®è¯»å–é”™è¯¯: {str(e)}")
            st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå¹¶åŒ…å«å¿…è¦çš„å­—æ®µã€‚")
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.matching_complete and st.session_state.analysis is not None:
        st.markdown("---")
        st.markdown('<h2 class="sub-header">ğŸ“Š åŒ¹é…åˆ†æç»“æœ</h2>', unsafe_allow_html=True)
        
        analysis = st.session_state.analysis
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…æ•°æ®
        if analysis.df_relations.empty:
            st.warning("âš ï¸ åŒ¹é…ç»“æœä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return
        
        # 1. æ¦‚è§ˆæŒ‡æ ‡
        analysis.create_summary_metrics()
        
        # 2. åŒ¹é…æ˜ç»†è¡¨
        st.markdown('<h3 class="sub-header">ğŸ“‹ åŒ¹é…æ˜ç»†è¡¨</h3>', unsafe_allow_html=True)
        detailed_table = analysis.create_match_detail_table(max_rows)
        
        if not detailed_table.empty:
            st.dataframe(detailed_table, use_container_width=True)
            st.caption(f"æ˜¾ç¤ºå‰ {len(detailed_table)} æ¡è®°å½•ï¼Œå…± {len(analysis.df_relations)} æ¡åŒ¹é…è®°å½•")
        else:
            st.info("æ— åŒ¹é…æ˜ç»†æ•°æ®å¯æ˜¾ç¤º")
        
        # 3. åˆ†æå›¾è¡¨
        if show_charts and not analysis.df_relations.empty:
            st.markdown('<h3 class="sub-header">ğŸ“ˆ å¯è§†åŒ–åˆ†æ</h3>', unsafe_allow_html=True)
            
            # å›¾è¡¨é€‰é¡¹å¡
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ğŸ“Š åŒ¹é…é‡åˆ†æ", "ğŸ’° P/Låˆ†æ", 
                "â±ï¸ æ—¶é—´åˆ†æ", "ğŸ’¹ ä»·æ ¼åˆ†æ", "ğŸ“… æœˆä»½åˆ†å¸ƒ"
            ])
            
            with tab1:
                fig1 = analysis.create_match_volume_chart()
                if fig1:
                    st.plotly_chart(fig1, use_container_width=True)
                else:
                    st.info("æ— åŒ¹é…é‡æ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
            
            with tab2:
                fig2 = analysis.create_simple_pl_chart()
                if fig2:
                    st.plotly_chart(fig2, use_container_width=True)
                    
                    # æ˜¾ç¤ºP/Lç»Ÿè®¡æ•°æ®
                    if 'Alloc_Total_PL' in analysis.df_relations.columns:
                        pl_stats = analysis.df_relations['Alloc_Total_PL'].describe()
                        st.dataframe(pl_stats, use_container_width=True)
                else:
                    st.info("æ— P/Læ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
            
            with tab3:
                fig3 = analysis.create_time_analysis_chart()
                if fig3:
                    st.plotly_chart(fig3, use_container_width=True)
                    
                    # æ˜¾ç¤ºæ—¶é—´å·®ç»Ÿè®¡æ•°æ®
                    if 'Time_Lag' in analysis.df_relations.columns:
                        time_stats = analysis.df_relations['Time_Lag'].describe()
                        st.dataframe(time_stats, use_container_width=True)
                else:
                    st.info("æ— æ—¶é—´å·®æ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
            
            with tab4:
                fig4 = analysis.create_price_analysis_chart()
                if fig4:
                    st.plotly_chart(fig4, use_container_width=True)
                    
                    # æ˜¾ç¤ºä»·æ ¼ç»Ÿè®¡æ•°æ®
                    if 'Open_Price' in analysis.df_relations.columns and 'MTM_Price' in analysis.df_relations.columns:
                        price_stats = pd.DataFrame({
                            'Open_Price': analysis.df_relations['Open_Price'].describe(),
                            'MTM_Price': analysis.df_relations['MTM_Price'].describe()
                        }).T
                        st.dataframe(price_stats, use_container_width=True)
                else:
                    st.info("æ— ä»·æ ¼æ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
            
            with tab5:
                fig5 = analysis.create_month_distribution_chart()
                if fig5:
                    st.plotly_chart(fig5, use_container_width=True)
                    
                    # æ˜¾ç¤ºæœˆä»½ç»Ÿè®¡æ•°æ®
                    if 'Month' in analysis.df_relations.columns:
                        month_stats = analysis.df_relations['Month'].value_counts()
                        st.dataframe(month_stats, use_container_width=True)
                else:
                    st.info("æ— æœˆä»½æ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
        
        # 4. é£é™©æŒ‡æ ‡
        if show_risk and not analysis.df_relations.empty:
            st.markdown('<h3 class="sub-header">âš ï¸ é£é™©æŒ‡æ ‡åˆ†æ</h3>', unsafe_allow_html=True)
            
            risk_metrics = analysis.create_risk_metrics()
            
            if risk_metrics:
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("VaR (95%)", f"${risk_metrics.get('VaR_95', 0):,.2f}")
                
                with col2:
                    st.metric("CVaR (95%)", f"${risk_metrics.get('CVaR_95', 0):,.2f}")
                
                with col3:
                    st.metric("å¤æ™®æ¯”ç‡", f"{risk_metrics.get('Sharpe_Ratio', 0):.2f}")
                
                with col4:
                    st.metric("æœ€å¤§å›æ’¤", f"{risk_metrics.get('Max_Drawdown', 0):.1f}%")
                
                # è¯¦ç»†é£é™©æŒ‡æ ‡è¡¨æ ¼
                with st.expander("æŸ¥çœ‹è¯¦ç»†é£é™©æŒ‡æ ‡"):
                    risk_df = pd.DataFrame.from_dict(risk_metrics, orient='index', columns=['å€¼'])
                    st.dataframe(risk_df.style.format("{:,.2f}"), use_container_width=True)
            else:
                st.info("æ— æ³•è®¡ç®—é£é™©æŒ‡æ ‡ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ•°æ®")
        
        # 5. æ•°æ®å¯¼å‡º
        st.markdown("---")
        st.markdown('<h3 class="sub-header">ğŸ’¾ æ•°æ®å¯¼å‡º</h3>', unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # å¯¼å‡ºåŒ¹é…ç»“æœ
            if not analysis.df_relations.empty:
                csv_data = analysis.df_relations.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åŒ¹é…ç»“æœ",
                    data=csv_data,
                    file_name=f"hedge_matching_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        with col2:
            # å¯¼å‡ºåˆ†ææŠ¥å‘Š
            report_data = {
                "åŒ¹é…ç»Ÿè®¡": analysis.summary_stats,
                "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "æ•°æ®é‡": {
                    "åŒ¹é…è®°å½•æ•°": len(analysis.df_relations),
                    "å®è´§è®°å½•æ•°": len(analysis.df_physical),
                    "çº¸è´§è®°å½•æ•°": len(analysis.df_paper_net) if analysis.df_paper_net is not None else 0
                }
            }
            
            report_json = json.dumps(report_data, indent=2, default=str, ensure_ascii=False)
            st.download_button(
                label="ğŸ“„ ä¸‹è½½åˆ†ææŠ¥å‘Š",
                data=report_json.encode('utf-8'),
                file_name=f"hedge_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
        
        with col3:
            # å¯¼å‡ºæ‰€æœ‰æ•°æ®
            @st.cache_data
            def convert_to_excel(df_dict):
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    for sheet_name, df in df_dict.items():
                        if df is not None and not df.empty:
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                return output.getvalue()
            
            if analysis.df_relations is not None:
                excel_data = convert_to_excel({
                    "åŒ¹é…ç»“æœ": analysis.df_relations,
                    "å®è´§æ•°æ®": analysis.df_physical,
                    "çº¸è´§å‡€ä»“": analysis.df_paper_net
                })
                
                st.download_button(
                    label="ğŸ“Š ä¸‹è½½å®Œæ•´æ•°æ®",
                    data=excel_data,
                    file_name=f"hedge_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
    
    else:
        # æ¬¢è¿é¡µé¢
        if not (paper_file and physical_file):
            st.markdown("---")
            st.markdown('<div class="info-box">ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ çº¸è´§å’Œå®è´§æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ</div>', unsafe_allow_html=True)
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("""
                ### ğŸ¯ ç³»ç»Ÿå·¥ä½œæµç¨‹
                
                1. **æ•°æ®ä¸Šä¼ **
                   - çº¸è´§äº¤æ˜“æ•°æ® (åŒ…å«äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡ã€å•†å“ã€ä»·æ ¼ç­‰)
                   - å®è´§æŒä»“æ•°æ® (åŒ…å«Cargo_IDã€äº¤æ˜“é‡ã€å¥—ä¿ä»£ç†ã€ç›®æ ‡æœˆä»½ç­‰)
                
                2. **æ™ºèƒ½åŒ¹é…**
                   - FIFOå†…éƒ¨å¯¹å†²ï¼šå…ˆå¯¹çº¸è´§è¿›è¡Œå‡€é¢åŒ–
                   - å®è´§åŒ¹é…ï¼šåŸºäºå“ç§ã€æœˆä»½ã€æ—¶é—´çš„æ™ºèƒ½åŒ¹é…
                   - BRENTä¼˜å…ˆï¼šä¼˜å…ˆåŒ¹é…BRENTåŸºå‡†çš„äº¤æ˜“
                
                3. **æ·±åº¦åˆ†æ**
                   - åŒ¹é…ç‡ä¸è¦†ç›–ç‡åˆ†æ
                   - P/Lä¸MTMåˆ†æ
                   - æ—¶é—´å·®ä¸æ•ˆç‡åˆ†æ
                   - é£é™©æŒ‡æ ‡è®¡ç®— (VaRã€å¤æ™®æ¯”ç‡ç­‰)
                
                4. **æ•°æ®å¯¼å‡º**
                   - åŒ¹é…ç»“æœCSV
                   - åˆ†ææŠ¥å‘ŠJSON
                   - å®Œæ•´æ•°æ®Excel
                """)
            
            with col2:
                st.markdown("""
                ### ğŸ“‹ æ•°æ®è¦æ±‚
                
                **çº¸è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Trade Date`: äº¤æ˜“æ—¥æœŸ
                - `Volume`: äº¤æ˜“é‡ (æ­£ä¹°è´Ÿå–)
                - `Commodity`: å•†å“å“ç§
                
                **å®è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Cargo_ID`: å®è´§ç¼–å·
                - `Volume`: äº¤æ˜“é‡
                - `Hedge_Proxy`: å¥—ä¿ä»£ç†
                
                **å¯é€‰å­—æ®µ:**
                - `Month`: åˆçº¦æœˆä»½
                - `Price`: äº¤æ˜“ä»·æ ¼
                - `Target_Contract_Month`: ç›®æ ‡æœˆä»½
                - `Designation_Date`: æŒ‡å®šæ—¥æœŸ
                """)

if __name__ == "__main__":
    main()
