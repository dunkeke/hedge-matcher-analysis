import streamlit as st
import pandas as pd
import numpy as np
import io
import time
import warnings
from datetime import datetime, timedelta
from collections import deque
import plotly.express as px
import plotly.graph_objects as go
import re
import json

warnings.filterwarnings("ignore", category=UserWarning)

# ---------------------------------------------------------
# 1. æ ¸å¿ƒåŒ¹é…å¼•æ“ (å®Œæ•´é›†æˆ)
# ---------------------------------------------------------

class HedgeMatchingEngine:
    """å¥—ä¿åŒ¹é…å¼•æ“ - å®Œæ•´ç‰ˆ"""
    
    def __init__(self):
        self.df_paper = None
        self.df_physical = None
        self.df_paper_net = None
        self.df_relations = None
        self.df_physical_updated = None
        
    def clean_str(self, series):
        """æ¸…æ´—å­—ç¬¦ä¸²"""
        return series.astype(str).str.strip().str.upper().replace('NAN', '')
    
    def standardize_month(self, series):
        """æ ‡å‡†åŒ–æœˆä»½æ ¼å¼"""
        s = series.astype(str).str.strip().str.upper()
        s = s.str.replace('-', ' ', regex=False).str.replace('/', ' ', regex=False)
        dates = pd.to_datetime(s, errors='coerce')
        result = dates.dt.strftime('%b %y').str.upper()
        mask_invalid = dates.isna()
        
        if mask_invalid.any():
            invalid = s[mask_invalid]
            def swap_if_match(val):
                m = re.match(r'^(\d{2})\s*([A-Z]{3})$', val)
                if m:
                    yr, mon = m.groups()
                    return f"{mon} {yr}"
                return val
            swapped = invalid.map(swap_if_match)
            swapped_dates = pd.to_datetime(swapped, errors='coerce')
            swapped_formatted = swapped_dates.dt.strftime('%b %y').str.upper()
            result.loc[mask_invalid & swapped_dates.notna()] = swapped_formatted.loc[swapped_dates.notna()]
            result.loc[mask_invalid & swapped_dates.isna()] = swapped.loc[swapped_dates.isna()]
        return result
    
    def calculate_net_positions(self, df_paper):
        """FIFOå‡€ä»“è®¡ç®—"""
        st.info("ğŸ”„ æ‰§è¡Œçº¸è´§å†…éƒ¨å¯¹å†² (FIFO Netting)...")
        progress_bar = st.progress(0)
        
        df_paper = df_paper.sort_values(by='Trade Date').reset_index(drop=True)
        df_paper['Group_Key'] = df_paper['Std_Commodity'] + "_" + df_paper['Month']
        records = df_paper.to_dict('records')
        groups = {}
        
        # åˆ†ç»„
        for i, row in enumerate(records):
            key = row['Group_Key']
            if key not in groups:
                groups[key] = []
            groups[key].append(i)
            if i % 100 == 0:
                progress_bar.progress(min(i / len(records) * 0.5, 0.5))
        
        # FIFOå‡€é¢åŒ–
        group_count = 0
        total_groups = len(groups)
        for key, indices in groups.items():
            open_queue = deque()
            for idx in indices:
                row = records[idx]
                current_vol = row.get('Volume', 0)
                records[idx]['Net_Open_Vol'] = current_vol
                records[idx]['Closed_Vol'] = 0
                records[idx]['Close_Events'] = []
                
                if abs(current_vol) < 0.0001:
                    continue
                
                current_sign = 1 if current_vol > 0 else -1
                
                # å°è¯•ä¸é˜Ÿåˆ—ä¸­çš„äº¤æ˜“æŠµæ¶ˆ
                while open_queue:
                    q_idx, q_vol, q_sign = open_queue[0]
                    if q_sign != current_sign:  # æ–¹å‘ç›¸åæ‰èƒ½æŠµæ¶ˆ
                        offset = min(abs(current_vol), abs(q_vol))
                        current_vol -= (current_sign * offset)
                        q_vol -= (q_sign * offset)
                        
                        # è®°å½•å¹³ä»“äº‹ä»¶
                        close_event = {
                            'Ref': str(records[idx].get('Recap No', '')),
                            'Date': records[idx].get('Trade Date'),
                            'Vol': offset,
                            'Price': records[idx].get('Price', 0)
                        }
                        records[q_idx]['Close_Events'].append(close_event)
                        records[q_idx]['Closed_Vol'] += offset
                        records[q_idx]['Net_Open_Vol'] = q_vol
                        records[idx]['Closed_Vol'] += offset
                        records[idx]['Net_Open_Vol'] = current_vol
                        
                        if abs(q_vol) < 0.0001:
                            open_queue.popleft()
                        else:
                            open_queue[0] = (q_idx, q_vol, q_sign)
                        
                        if abs(current_vol) < 0.0001:
                            break
                    else:
                        break
                
                # å‰©ä½™éƒ¨åˆ†å…¥é˜Ÿ
                if abs(current_vol) > 0.0001:
                    open_queue.append((idx, current_vol, current_sign))
            
            group_count += 1
            progress_bar.progress(0.5 + (group_count / total_groups) * 0.5)
        
        progress_bar.progress(1.0)
        st.success(f"âœ… çº¸è´§å†…éƒ¨å¯¹å†²å®Œæˆï¼å…±å¤„ç† {len(groups)} ä¸ªå•†å“-æœˆä»½ç»„åˆ")
        return pd.DataFrame(records)
    
    def match_hedges(self, df_physical, df_paper_net):
        """å®è´§åŒ¹é…"""
        st.info("ğŸ”„ å¼€å§‹å®è´§åŒ¹é…...")
        progress_bar = st.progress(0)
        
        hedge_relations = []
        active_paper = df_paper_net.copy()
        active_paper['Allocated_To_Phy'] = 0.0
        active_paper['_original_index'] = active_paper.index
        
        df_phy = df_physical.copy()
        df_phy['_orig_idx'] = df_phy.index
        
        # BRENTä¼˜å…ˆåŒ¹é…
        if 'Pricing_Benchmark' in df_phy.columns:
            def bench_prio(x):
                x_str = str(x).upper()
                return 0 if 'BRENT' in x_str else 1
            df_phy['_priority'] = df_phy['Pricing_Benchmark'].apply(bench_prio)
            df_phy = df_phy.sort_values(by=['_priority', '_orig_idx']).reset_index(drop=True)
            df_phy = df_phy.drop(columns=['_priority'])
        else:
            df_phy = df_phy.reset_index(drop=True)
        
        total_cargos = len(df_phy)
        
        for idx, (_, cargo) in enumerate(df_phy.iterrows()):
            cargo_id = cargo.get('Cargo_ID')
            phy_vol = cargo.get('Unhedged_Volume', 0)
            
            if abs(phy_vol) < 0.0001:
                continue
            
            proxy = str(cargo.get('Hedge_Proxy', ''))
            target_month = cargo.get('Target_Contract_Month', None)
            phy_dir = cargo.get('Direction', 'Buy')
            desig_date = cargo.get('Designation_Date', pd.NaT)
            
            # ç­›é€‰å€™é€‰äº¤æ˜“
            candidates_df = active_paper[
                (active_paper['Std_Commodity'].str.contains(proxy, regex=False)) &
                (active_paper['Month'] == target_month)
            ].copy()
            
            if candidates_df.empty:
                continue
            
            # æ—¶é—´æ’åºï¼šæœ‰æŒ‡å®šæ—¥æœŸæŒ‰æ—¶é—´å·®ï¼Œå¦åˆ™FIFO
            if pd.notna(desig_date) and not candidates_df['Trade Date'].isnull().all():
                candidates_df['Time_Lag_Days'] = (candidates_df['Trade Date'] - desig_date).dt.days
                candidates_df['Abs_Lag'] = candidates_df['Time_Lag_Days'].abs()
                candidates_df = candidates_df.sort_values(by=['Abs_Lag', 'Trade Date'])
            else:
                candidates_df['Time_Lag_Days'] = np.nan
                candidates_df = candidates_df.sort_values(by='Trade Date')
            
            # åˆ†é…åŒ¹é…
            for _, ticket in candidates_df.iterrows():
                if abs(phy_vol) < 1:
                    break
                
                original_index = ticket['_original_index']
                curr_allocated = active_paper.at[original_index, 'Allocated_To_Phy']
                curr_total_vol = ticket.get('Volume', 0)
                avail = curr_total_vol - curr_allocated
                
                if abs(avail) < 0.0001:
                    continue
                
                alloc_amt_abs = abs(phy_vol) if abs(avail) >= abs(phy_vol) else abs(avail)
                alloc_amt = np.sign(avail) * alloc_amt_abs
                phy_vol -= alloc_amt_abs
                active_paper.at[original_index, 'Allocated_To_Phy'] += alloc_amt
                
                # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
                open_price = ticket.get('Price', 0)
                mtm_price = ticket.get('Mtm Price', open_price)  # é»˜è®¤ä¸ºå¼€ä»“ä»·
                total_pl_raw = ticket.get('Total P/L', 0)
                close_events = ticket.get('Close_Events', [])
                
                # æ ¼å¼åŒ–å¹³ä»“è·¯å¾„
                close_path_str = ""
                if close_events:
                    sorted_events = sorted(close_events, key=lambda x: x['Date'] if pd.notna(x['Date']) else pd.Timestamp.min)
                    details = []
                    for e in sorted_events:
                        d_str = e['Date'].strftime('%Y-%m-%d') if pd.notna(e['Date']) else 'N/A'
                        p_str = f"@{e['Price']}" if pd.notna(e['Price']) else ""
                        details.append(f"[{d_str} Tkt#{e['Ref']} Vol:{e['Vol']:.0f} {p_str}]")
                    close_path_str = " -> ".join(details)
                
                # è®¡ç®—åˆ†é…æ¯”ä¾‹
                ratio = abs(alloc_amt) / abs(curr_total_vol) if abs(curr_total_vol) > 0 else 0
                unrealized_mtm = (mtm_price - open_price) * alloc_amt
                allocated_total_pl = total_pl_raw * ratio
                
                hedge_relations.append({
                    'Cargo_ID': cargo_id,
                    'Proxy': proxy,
                    'Designation_Date': desig_date,
                    'Open_Date': ticket.get('Trade Date'),
                    'Time_Lag': ticket.get('Time_Lag_Days'),
                    'Ticket_ID': ticket.get('Recap No'),
                    'Month': ticket.get('Month'),
                    'Allocated_Vol': alloc_amt,
                    'Trade_Volume': ticket.get('Volume', 0),
                    'Trade_Net_Open': ticket.get('Net_Open_Vol', 0),
                    'Trade_Closed_Vol': ticket.get('Closed_Vol', 0),
                    'Open_Price': open_price,
                    'MTM_Price': mtm_price,
                    'Alloc_Unrealized_MTM': round(unrealized_mtm, 2),
                    'Alloc_Total_PL': round(allocated_total_pl, 2),
                    'Close_Path_Details': close_path_str,
                })
                
                # æ›´æ–°å®è´§æœªå¯¹å†²é‡
                orig_idx = cargo.get('_orig_idx')
                if orig_idx in df_physical.index:
                    df_physical.at[orig_idx, 'Unhedged_Volume'] = phy_vol
            
            progress_bar.progress((idx + 1) / total_cargos)
        
        # æ›´æ–°åˆ†é…é‡
        cols_to_update = active_paper[['_original_index', 'Allocated_To_Phy']].set_index('_original_index')
        df_paper_net.update(cols_to_update)
        
        progress_bar.progress(1.0)
        df_relations = pd.DataFrame(hedge_relations)
        st.success(f"âœ… å®è´§åŒ¹é…å®Œæˆï¼å…±ç”Ÿæˆ {len(df_relations)} æ¡åŒ¹é…è®°å½•")
        
        return df_relations, df_physical
    
    def run_matching(self, df_paper_raw, df_physical_raw):
        """æ‰§è¡Œå®Œæ•´åŒ¹é…æµç¨‹"""
        # æ•°æ®é¢„å¤„ç†
        st.info("ğŸ”„ æ•°æ®é¢„å¤„ç†ä¸­...")
        
        # çº¸è´§é¢„å¤„ç†
        df_paper = df_paper_raw.copy()
        
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        required_cols_paper = ['Trade Date', 'Volume', 'Commodity']
        for col in required_cols_paper:
            if col not in df_paper.columns:
                st.error(f"çº¸è´§æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {col}")
                return None, None, None, None
        
        # æ ‡å‡†åŒ–å¤„ç†
        df_paper['Trade Date'] = pd.to_datetime(df_paper['Trade Date'], errors='coerce')
        df_paper['Volume'] = pd.to_numeric(df_paper['Volume'], errors='coerce').fillna(0)
        df_paper['Std_Commodity'] = self.clean_str(df_paper['Commodity'])
        
        if 'Month' in df_paper.columns:
            df_paper['Month'] = self.standardize_month(df_paper['Month'])
        else:
            # å¦‚æœæ²¡æœ‰Monthåˆ—ï¼Œå°è¯•ä»å…¶ä»–åˆ—æ¨æ–­æˆ–åˆ›å»ºé»˜è®¤å€¼
            df_paper['Month'] = df_paper['Trade Date'].dt.strftime('%b %y').str.upper()
        
        # å¤„ç†ç¼ºå¤±å­—æ®µ
        if 'Recap No' not in df_paper.columns:
            df_paper['Recap No'] = [f"TKT-{i+1:04d}" for i in range(len(df_paper))]
        
        for col in ['Price', 'Mtm Price', 'Total P/L']:
            if col not in df_paper.columns:
                df_paper[col] = 0.0
        
        # å®è´§é¢„å¤„ç†
        df_physical = df_physical_raw.copy()
        
        # æ ‡å‡†åŒ–åˆ—å
        col_mapping = {
            'Target_Pricing_Month': 'Target_Contract_Month',
            'Month': 'Target_Contract_Month',
            'Hedge_Proxy': 'Hedge_Proxy',
            'Direction': 'Direction'
        }
        
        for old_col, new_col in col_mapping.items():
            if old_col in df_physical.columns and new_col not in df_physical.columns:
                df_physical[new_col] = df_physical[old_col]
        
        # ç¡®ä¿å¿…è¦åˆ—
        if 'Volume' in df_physical.columns:
            df_physical['Volume'] = pd.to_numeric(df_physical['Volume'], errors='coerce').fillna(0)
            df_physical['Unhedged_Volume'] = df_physical['Volume']
        
        if 'Hedge_Proxy' in df_physical.columns:
            df_physical['Hedge_Proxy'] = self.clean_str(df_physical['Hedge_Proxy'])
        
        if 'Target_Contract_Month' in df_physical.columns:
            df_physical['Target_Contract_Month'] = self.standardize_month(df_physical['Target_Contract_Month'])
        
        # æŒ‡å®šæ—¥æœŸ
        date_cols = ['Designation_Date', 'Pricing_Start', 'Trade Date']
        for col in date_cols:
            if col in df_physical.columns:
                df_physical['Designation_Date'] = pd.to_datetime(df_physical[col], errors='coerce')
                break
        else:
            df_physical['Designation_Date'] = pd.NaT
        
        # æ‰§è¡ŒåŒ¹é…
        self.df_paper_net = self.calculate_net_positions(df_paper)
        self.df_relations, self.df_physical_updated = self.match_hedges(df_physical, self.df_paper_net)
        
        return self.df_relations, self.df_physical_updated, self.df_paper_net, df_paper

# ---------------------------------------------------------
# 2. åˆ†ææ¨¡å— (åŸºäºçœŸå®åŒ¹é…ç»“æœ)
# ---------------------------------------------------------

class HedgeAnalysis:
    """å¥—ä¿åˆ†ææ¨¡å—"""
    
    def __init__(self, df_relations, df_physical, df_paper_net):
        self.df_relations = df_relations
        self.df_physical = df_physical
        self.df_paper_net = df_paper_net
        self.summary_stats = {}
        self.calculate_summary()
    
    def calculate_summary(self):
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        if self.df_relations.empty:
            return
        
        # åŒ¹é…ç»Ÿè®¡
        total_matched = abs(self.df_relations['Allocated_Vol']).sum()
        total_physical = abs(self.df_physical['Volume']).sum() if 'Volume' in self.df_physical.columns else 0
        match_rate = (total_matched / total_physical * 100) if total_physical > 0 else 0
        
        # è´¢åŠ¡ç»Ÿè®¡
        total_pl = self.df_relations['Alloc_Total_PL'].sum()
        total_unrealized = self.df_relations['Alloc_Unrealized_MTM'].sum()
        
        # æ•°é‡ç»Ÿè®¡
        matched_cargos = self.df_relations['Cargo_ID'].nunique()
        total_cargos = self.df_physical['Cargo_ID'].nunique() if 'Cargo_ID' in self.df_physical.columns else 0
        total_tickets = len(self.df_relations)
        
        # æ—¶é—´ç»Ÿè®¡
        if 'Time_Lag' in self.df_relations.columns:
            avg_time_lag = self.df_relations['Time_Lag'].abs().mean()
            std_time_lag = self.df_relations['Time_Lag'].abs().std()
        else:
            avg_time_lag = std_time_lag = 0
        
        self.summary_stats = {
            'total_matched': total_matched,
            'total_physical': total_physical,
            'match_rate': match_rate,
            'total_pl': total_pl,
            'total_unrealized': total_unrealized,
            'matched_cargos': matched_cargos,
            'total_cargos': total_cargos,
            'total_tickets': total_tickets,
            'avg_time_lag': avg_time_lag,
            'std_time_lag': std_time_lag
        }
    
    def create_summary_metrics(self):
        """åˆ›å»ºæ¦‚è§ˆæŒ‡æ ‡å¡ç‰‡"""
        stats = self.summary_stats
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“Š åŒ¹é…ç‡", f"{stats['match_rate']:.1f}%", 
                     delta=f"{stats['total_matched']:,.0f}/{stats['total_physical']:,.0f}")
        
        with col2:
            coverage = (stats['matched_cargos'] / stats['total_cargos'] * 100) if stats['total_cargos'] > 0 else 0
            st.metric("ğŸ“¦ åŒ¹é…è¦†ç›–ç‡", f"{coverage:.1f}%",
                     delta=f"{stats['matched_cargos']}/{stats['total_cargos']}")
        
        with col3:
            st.metric("ğŸ’° æ€»P/L", f"${stats['total_pl']:,.2f}",
                     delta=f"æœªå®ç°: ${stats['total_unrealized']:,.2f}")
        
        with col4:
            st.metric("â±ï¸ å¹³å‡æ—¶é—´å·®", f"{stats['avg_time_lag']:.1f}å¤©",
                     delta=f"Â±{stats['std_time_lag']:.1f}å¤©")
    
    def create_match_volume_chart(self):
        """åŒ¹é…é‡åˆ†å¸ƒå›¾è¡¨"""
        if self.df_relations.empty:
            return None
        
        # æŒ‰Cargo_IDæ±‡æ€»
        cargo_summary = self.df_relations.copy()
        cargo_summary['Allocated_Vol_Abs'] = abs(cargo_summary['Allocated_Vol'])
        cargo_summary = cargo_summary.groupby('Cargo_ID')['Allocated_Vol_Abs'].sum().reset_index()
        
        fig = px.bar(cargo_summary.sort_values('Allocated_Vol_Abs', ascending=False).head(20), 
                     x='Cargo_ID', y='Allocated_Vol_Abs',
                     title='ğŸ“ˆ å„Cargo_IDåŒ¹é…é‡TOP20',
                     labels={'Allocated_Vol_Abs': 'åŒ¹é…é‡', 'Cargo_ID': 'å®è´§ç¼–å·'},
                     color='Allocated_Vol_Abs',
                     color_continuous_scale='Viridis')
        fig.update_layout(xaxis_tickangle=-45)
        return fig
    
    def create_pl_analysis_chart(self):
        """P/Låˆ†æå›¾è¡¨"""
        if self.df_relations.empty:
            return None
        
        # åˆ›å»ºå­å›¾
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('ğŸ’° P/Låˆ†å¸ƒç›´æ–¹å›¾', 'ğŸ“Š P/LæŒ‰Cargo_IDåˆ†å¸ƒ',
                           'ğŸ“… P/LæŒ‰æœˆä»½åˆ†å¸ƒ', 'ğŸ“ˆ P/Lç´¯è®¡æ›²çº¿'),
            vertical_spacing=0.15,
            horizontal_spacing=0.1
        )
        
        # 1. P/Lç›´æ–¹å›¾
        fig.add_trace(
            go.Histogram(x=self.df_relations['Alloc_Total_PL'], nbinsx=30,
                        name='P/Låˆ†å¸ƒ'),
            row=1, col=1
        )
        fig.add_vline(x=0, line_dash="dash", line_color="red", row=1, col=1)
        
        # 2. æŒ‰Cargo_IDçš„P/Låˆ†å¸ƒ
        if 'Cargo_ID' in self.df_relations.columns:
            cargo_pl = self.df_relations.groupby('Cargo_ID')['Alloc_Total_PL'].sum().reset_index()
            fig.add_trace(
                go.Bar(x=cargo_pl['Cargo_ID'], y=cargo_pl['Alloc_Total_PL'],
                      name='æŒ‰Cargo_ID'),
                row=1, col=2
            )
            fig.update_xaxes(tickangle=-45, row=1, col=2)
        
        # 3. æŒ‰æœˆä»½çš„P/Låˆ†å¸ƒ
        if 'Month' in self.df_relations.columns:
            month_pl = self.df_relations.groupby('Month')['Alloc_Total_PL'].sum().reset_index()
            fig.add_trace(
                go.Bar(x=month_pl['Month'], y=month_pl['Alloc_Total_PL'],
                      name='æŒ‰æœˆä»½'),
                row=2, col=1
            )
            fig.update_xaxes(tickangle=-45, row=2, col=1)
        
        # 4. P/Lç´¯è®¡æ›²çº¿
        sorted_pl = self.df_relations.sort_values('Alloc_Total_PL')['Alloc_Total_PL']
        cumulative_pl = sorted_pl.cumsum()
        fig.add_trace(
            go.Scatter(x=np.arange(len(cumulative_pl)), y=cumulative_pl,
                      mode='lines', name='ç´¯è®¡P/L'),
            row=2, col=2
        )
        fig.add_hline(y=0, line_dash="dash", line_color="red", row=2, col=2)
        
        fig.update_layout(height=700, showlegend=False)
        return fig
    
    def create_time_analysis_chart(self):
        """æ—¶é—´åˆ†æå›¾è¡¨"""
        if self.df_relations.empty or 'Time_Lag' not in self.df_relations.columns:
            return None
        
        time_lag_data = self.df_relations['Time_Lag'].dropna()
        if time_lag_data.empty:
            return None
        
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=('â±ï¸ æ—¶é—´å·®åˆ†å¸ƒ', 'ğŸ“… æ—¶é—´å·®ä¸P/Lå…³ç³»'),
            specs=[[{"type": "histogram"}, {"type": "scatter"}]]
        )
        
        # æ—¶é—´å·®åˆ†å¸ƒ
        fig.add_trace(
            go.Histogram(x=time_lag_data, nbinsx=30,
                        name='æ—¶é—´å·®åˆ†å¸ƒ'),
            row=1, col=1
        )
        fig.add_vline(x=0, line_dash="dash", line_color="green",
                     annotation_text="å®Œç¾åŒ¹é…", row=1, col=1)
        
        # æ—¶é—´å·®ä¸P/Lå…³ç³»
        if 'Alloc_Total_PL' in self.df_relations.columns:
            fig.add_trace(
                go.Scatter(x=self.df_relations['Time_Lag'],
                          y=self.df_relations['Alloc_Total_PL'],
                          mode='markers',
                          marker=dict(size=8, 
                                     color=self.df_relations['Allocated_Vol'],
                                     colorscale='Viridis',
                                     showscale=True,
                                     colorbar=dict(title="åˆ†é…é‡")),
                          name='æ—¶é—´å·® vs P/L',
                          text=self.df_relations['Cargo_ID']),
                row=1, col=2
            )
            fig.add_hline(y=0, line_dash="dash", line_color="red", row=1, col=2)
            fig.add_vline(x=0, line_dash="dash", line_color="green", row=1, col=2)
        
        fig.update_layout(height=400)
        return fig
    
    def create_price_analysis_chart(self):
        """ä»·æ ¼åˆ†æå›¾è¡¨"""
        if self.df_relations.empty or 'Open_Price' not in self.df_relations.columns:
            return None
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('ğŸ’¹ å¼€ä»“ä»·åˆ†å¸ƒ', 'ğŸ“Š ä»·æ ¼å·®å¼‚åˆ†æ',
                           'ğŸ’° ä»·æ ¼ä¸P/Lå…³ç³»', 'ğŸ“ˆ ä»·æ ¼èµ°åŠ¿æ¨¡æ‹Ÿ'),
            vertical_spacing=0.15
        )
        
        # 1. å¼€ä»“ä»·åˆ†å¸ƒ
        fig.add_trace(
            go.Histogram(x=self.df_relations['Open_Price'], nbinsx=20,
                        name='å¼€ä»“ä»·åˆ†å¸ƒ'),
            row=1, col=1
        )
        
        # 2. ä»·æ ¼å·®å¼‚åˆ†æ
        if 'MTM_Price' in self.df_relations.columns:
            price_diff = self.df_relations['MTM_Price'] - self.df_relations['Open_Price']
            price_diff_pct = (price_diff / self.df_relations['Open_Price'] * 100).fillna(0)
            
            fig.add_trace(
                go.Histogram(x=price_diff_pct, nbinsx=20,
                            name='ä»·æ ¼å·®å¼‚%'),
                row=1, col=2
            )
            fig.add_vline(x=0, line_dash="dash", line_color="red", row=1, col=2)
        
        # 3. ä»·æ ¼ä¸P/Lå…³ç³»
        if 'Alloc_Total_PL' in self.df_relations.columns:
            fig.add_trace(
                go.Scatter(x=self.df_relations['Open_Price'],
                          y=self.df_relations['Alloc_Total_PL'],
                          mode='markers',
                          marker=dict(size=8,
                                     color=abs(self.df_relations['Allocated_Vol']),
                                     colorscale='Plasma',
                                     showscale=True),
                          name='ä»·æ ¼ vs P/L'),
                row=2, col=1
            )
        
        # 4. ä»·æ ¼èµ°åŠ¿æ¨¡æ‹Ÿ
        if 'Open_Date' in self.df_relations.columns:
            daily_prices = self.df_relations.groupby('Open_Date')['Open_Price'].mean().reset_index()
            daily_prices = daily_prices.sort_values('Open_Date')
            
            fig.add_trace(
                go.Scatter(x=daily_prices['Open_Date'],
                          y=daily_prices['Open_Price'],
                          mode='lines+markers',
                          name='å¹³å‡å¼€ä»“ä»·èµ°åŠ¿'),
                row=2, col=2
            )
        
        fig.update_layout(height=600, showlegend=False)
        return fig
    
    def create_match_detail_table(self, max_rows=50):
        """åˆ›å»ºåŒ¹é…æ˜ç»†è¡¨"""
        if self.df_relations.empty:
            return pd.DataFrame()
        
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
        display_cols = []
        possible_cols = ['Cargo_ID', 'Ticket_ID', 'Month', 'Allocated_Vol',
                        'Open_Price', 'MTM_Price', 'Alloc_Total_PL',
                        'Alloc_Unrealized_MTM', 'Time_Lag', 'Proxy']
        
        for col in possible_cols:
            if col in self.df_relations.columns:
                display_cols.append(col)
        
        # æ ¼å¼åŒ–æ•°å­—
        formatted_df = self.df_relations[display_cols].copy()
        
        # æ•°å­—æ ¼å¼åŒ–å‡½æ•°
        def format_number(x):
            if isinstance(x, (int, float, np.integer, np.floating)):
                return f"{x:,.2f}"
            return x
        
        # æ ¼å¼åŒ–æ•°å€¼åˆ—
        num_cols = ['Allocated_Vol', 'Open_Price', 'MTM_Price', 
                   'Alloc_Total_PL', 'Alloc_Unrealized_MTM']
        for col in num_cols:
            if col in formatted_df.columns:
                formatted_df[col] = formatted_df[col].apply(format_number)
        
        return formatted_df.head(max_rows)
    
    def create_risk_metrics(self):
        """é£é™©æŒ‡æ ‡è®¡ç®—"""
        if self.df_relations.empty:
            return {}
        
        risk_metrics = {}
        
        # VaRè®¡ç®— (95%ç½®ä¿¡æ°´å¹³)
        if 'Alloc_Total_PL' in self.df_relations.columns:
            pl_series = self.df_relations['Alloc_Total_PL']
            var_95 = np.percentile(pl_series, 5)  # 95% VaR
            cvar_95 = pl_series[pl_series <= var_95].mean()  # æ¡ä»¶VaR
            risk_metrics['VaR_95'] = var_95
            risk_metrics['CVaR_95'] = cvar_95
            risk_metrics['PL_StdDev'] = pl_series.std()
            risk_metrics['PL_Max'] = pl_series.max()
            risk_metrics['PL_Min'] = pl_series.min()
        
        # å¤æ™®æ¯”ç‡ (å‡è®¾æ— é£é™©åˆ©ç‡ä¸º0)
        if 'Alloc_Total_PL' in self.df_relations.columns and len(self.df_relations) > 1:
            avg_pl = self.df_relations['Alloc_Total_PL'].mean()
            std_pl = self.df_relations['Alloc_Total_PL'].std()
            risk_metrics['Sharpe_Ratio'] = avg_pl / std_pl if std_pl != 0 else 0
        
        # æœ€å¤§å›æ’¤
        if 'Alloc_Total_PL' in self.df_relations.columns:
            pl_cumulative = self.df_relations['Alloc_Total_PL'].cumsum()
            running_max = pl_cumulative.expanding().max()
            drawdown = (pl_cumulative - running_max) / running_max * 100
            risk_metrics['Max_Drawdown'] = drawdown.min()
        
        return risk_metrics

# ---------------------------------------------------------
# 3. Streamlit ä¸»åº”ç”¨
# ---------------------------------------------------------

def main():
    st.set_page_config(
        page_title="å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #374151;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        border-bottom: 2px solid #E5E7EB;
        padding-bottom: 0.5rem;
    }
    .success-box {
        background-color: #D1FAE5;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #10B981;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #DBEAFE;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3B82F6;
        margin: 1rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ“ˆ å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    st.markdown("### ä¸“ä¸šå¥—ä¿åŒ¹é…ä¸é£é™©åˆ†æå·¥å…· | åŸºäºçœŸå®åŒ¹é…æ•°æ®")
    
    # åˆå§‹åŒ–session state
    if 'engine' not in st.session_state:
        st.session_state.engine = HedgeMatchingEngine()
    if 'analysis' not in st.session_state:
        st.session_state.analysis = None
    if 'matching_complete' not in st.session_state:
        st.session_state.matching_complete = False
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.markdown("### ğŸ“ æ•°æ®ä¸Šä¼ ")
        
        paper_file = st.file_uploader(
            "çº¸è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="paper_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Trade Date, Volume, Commodityç­‰å­—æ®µ"
        )
        
        physical_file = st.file_uploader(
            "å®è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="physical_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Cargo_ID, Volume, Hedge_Proxyç­‰å­—æ®µ"
        )
        
        st.markdown("---")
        st.markdown("### âš™ï¸ åˆ†æè®¾ç½®")
        
        show_charts = st.checkbox("æ˜¾ç¤ºåˆ†æå›¾è¡¨", value=True)
        show_risk = st.checkbox("æ˜¾ç¤ºé£é™©æŒ‡æ ‡", value=True)
        max_rows = st.slider("è¡¨æ ¼æ˜¾ç¤ºè¡Œæ•°", 10, 200, 50)
        
        st.markdown("---")
        
        if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰æ•°æ®", type="secondary"):
            st.session_state.engine = HedgeMatchingEngine()
            st.session_state.analysis = None
            st.session_state.matching_complete = False
            st.rerun()
    
    # ä¸»å†…å®¹åŒº
    if paper_file is not None and physical_file is not None:
        # è¯»å–æ•°æ®
        try:
            # è¯»å–çº¸è´§æ•°æ®
            if paper_file.name.endswith(('.xlsx', '.xls')):
                df_paper_raw = pd.read_excel(paper_file)
            else:
                df_paper_raw = pd.read_csv(paper_file)
            
            # è¯»å–å®è´§æ•°æ®
            if physical_file.name.endswith(('.xlsx', '.xls')):
                df_physical_raw = pd.read_excel(physical_file)
            else:
                df_physical_raw = pd.read_csv(physical_file)
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            with st.expander("ğŸ“‹ åŸå§‹æ•°æ®é¢„è§ˆ", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**çº¸è´§æ•°æ®** ({len(df_paper_raw)}è¡Œ, {len(df_paper_raw.columns)}åˆ—)")
                    st.dataframe(df_paper_raw.head(10), use_container_width=True)
                    st.caption(f"å…³é”®å­—æ®µ: {', '.join(df_paper_raw.columns.tolist()[:5])}...")
                
                with col2:
                    st.markdown(f"**å®è´§æ•°æ®** ({len(df_physical_raw)}è¡Œ, {len(df_physical_raw.columns)}åˆ—)")
                    st.dataframe(df_physical_raw.head(10), use_container_width=True)
                    st.caption(f"å…³é”®å­—æ®µ: {', '.join(df_physical_raw.columns.tolist()[:5])}...")
            
            # æ‰§è¡ŒåŒ¹é…æŒ‰é’®
            if st.button("ğŸš€ æ‰§è¡Œå¥—ä¿åŒ¹é…", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨æ‰§è¡Œå¥—ä¿åŒ¹é…ï¼Œè¯·ç¨å€™..."):
                    try:
                        # æ‰§è¡ŒåŒ¹é…
                        df_relations, df_physical_updated, df_paper_net, df_paper_processed = st.session_state.engine.run_matching(
                            df_paper_raw, df_physical_raw
                        )
                        
                        if df_relations is not None:
                            # åˆ›å»ºåˆ†ææ¨¡å—
                            st.session_state.analysis = HedgeAnalysis(
                                df_relations, df_physical_updated, df_paper_net
                            )
                            st.session_state.matching_complete = True
                            
                            # æ˜¾ç¤ºåŒ¹é…æˆåŠŸä¿¡æ¯
                            st.markdown('<div class="success-box">âœ… å¥—ä¿åŒ¹é…æˆåŠŸå®Œæˆï¼</div>', unsafe_allow_html=True)
                            
                            # æ˜¾ç¤ºåŒ¹é…è¿‡ç¨‹æ•°æ®
                            with st.expander("ğŸ“Š åŒ¹é…è¿‡ç¨‹æ•°æ®", expanded=False):
                                tab1, tab2, tab3 = st.tabs(["çº¸è´§å‡€ä»“", "å®è´§æ›´æ–°", "åŒ¹é…å…³ç³»"])
                                
                                with tab1:
                                    st.dataframe(df_paper_net.head(20), use_container_width=True)
                                    st.caption(f"çº¸è´§å‡€ä»“æ•°æ® ({len(df_paper_net)}è¡Œ)")
                                
                                with tab2:
                                    st.dataframe(df_physical_updated.head(20), use_container_width=True)
                                    st.caption(f"æ›´æ–°åå®è´§æ•°æ® ({len(df_physical_updated)}è¡Œ)")
                                
                                with tab3:
                                    st.dataframe(df_relations.head(20), use_container_width=True)
                                    st.caption(f"åŒ¹é…å…³ç³»æ•°æ® ({len(df_relations)}è¡Œ)")
                        else:
                            st.error("åŒ¹é…è¿‡ç¨‹å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼ã€‚")
                            
                    except Exception as e:
                        st.error(f"åŒ¹é…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                        st.exception(e)
        
        except Exception as e:
            st.error(f"æ•°æ®è¯»å–é”™è¯¯: {str(e)}")
            st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå¹¶åŒ…å«å¿…è¦çš„å­—æ®µã€‚")
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.matching_complete and st.session_state.analysis is not None:
        st.markdown("---")
        st.markdown('<h2 class="sub-header">ğŸ“Š åŒ¹é…åˆ†æç»“æœ</h2>', unsafe_allow_html=True)
        
        analysis = st.session_state.analysis
        
        # 1. æ¦‚è§ˆæŒ‡æ ‡
        analysis.create_summary_metrics()
        
        # 2. åŒ¹é…æ˜ç»†è¡¨
        st.markdown('<h3 class="sub-header">ğŸ“‹ åŒ¹é…æ˜ç»†è¡¨</h3>', unsafe_allow_html=True)
        detailed_table = analysis.create_match_detail_table(max_rows)
        st.dataframe(detailed_table, use_container_width=True)
        st.caption(f"æ˜¾ç¤ºå‰ {len(detailed_table)} æ¡è®°å½•ï¼Œå…± {len(analysis.df_relations)} æ¡åŒ¹é…è®°å½•")
        
        # 3. åˆ†æå›¾è¡¨
        if show_charts and not analysis.df_relations.empty:
            st.markdown('<h3 class="sub-header">ğŸ“ˆ å¯è§†åŒ–åˆ†æ</h3>', unsafe_allow_html=True)
            
            # å›¾è¡¨é€‰é¡¹å¡
            tab1, tab2, tab3, tab4 = st.tabs([
                "ğŸ“Š åŒ¹é…é‡åˆ†æ", "ğŸ’° P/Låˆ†æ", 
                "â±ï¸ æ—¶é—´åˆ†æ", "ğŸ’¹ ä»·æ ¼åˆ†æ"
            ])
            
            with tab1:
                fig1 = analysis.create_match_volume_chart()
                if fig1:
                    st.plotly_chart(fig1, use_container_width=True)
                else:
                    st.info("æ— åŒ¹é…é‡æ•°æ®")
            
            with tab2:
                fig2 = analysis.create_pl_analysis_chart()
                if fig2:
                    st.plotly_chart(fig2, use_container_width=True)
                else:
                    st.info("æ— P/Læ•°æ®")
            
            with tab3:
                fig3 = analysis.create_time_analysis_chart()
                if fig3:
                    st.plotly_chart(fig3, use_container_width=True)
                else:
                    st.info("æ— æ—¶é—´å·®æ•°æ®")
            
            with tab4:
                fig4 = analysis.create_price_analysis_chart()
                if fig4:
                    st.plotly_chart(fig4, use_container_width=True)
                else:
                    st.info("æ— ä»·æ ¼æ•°æ®")
        
        # 4. é£é™©æŒ‡æ ‡
        if show_risk and not analysis.df_relations.empty:
            st.markdown('<h3 class="sub-header">âš ï¸ é£é™©æŒ‡æ ‡åˆ†æ</h3>', unsafe_allow_html=True)
            
            risk_metrics = analysis.create_risk_metrics()
            
            if risk_metrics:
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("VaR (95%)", f"${risk_metrics.get('VaR_95', 0):,.2f}")
                
                with col2:
                    st.metric("CVaR (95%)", f"${risk_metrics.get('CVaR_95', 0):,.2f}")
                
                with col3:
                    st.metric("å¤æ™®æ¯”ç‡", f"{risk_metrics.get('Sharpe_Ratio', 0):.2f}")
                
                with col4:
                    st.metric("æœ€å¤§å›æ’¤", f"{risk_metrics.get('Max_Drawdown', 0):.1f}%")
                
                # è¯¦ç»†é£é™©æŒ‡æ ‡è¡¨æ ¼
                with st.expander("æŸ¥çœ‹è¯¦ç»†é£é™©æŒ‡æ ‡"):
                    risk_df = pd.DataFrame.from_dict(risk_metrics, orient='index', columns=['å€¼'])
                    st.dataframe(risk_df.style.format("{:,.2f}"), use_container_width=True)
        
        # 5. æ•°æ®å¯¼å‡º
        st.markdown("---")
        st.markdown('<h3 class="sub-header">ğŸ’¾ æ•°æ®å¯¼å‡º</h3>', unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # å¯¼å‡ºåŒ¹é…ç»“æœ
            if not analysis.df_relations.empty:
                csv_data = analysis.df_relations.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åŒ¹é…ç»“æœ",
                    data=csv_data,
                    file_name=f"hedge_matching_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        with col2:
            # å¯¼å‡ºåˆ†ææŠ¥å‘Š
            report_data = {
                "åŒ¹é…ç»Ÿè®¡": analysis.summary_stats,
                "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "æ•°æ®é‡": {
                    "åŒ¹é…è®°å½•æ•°": len(analysis.df_relations),
                    "å®è´§è®°å½•æ•°": len(analysis.df_physical),
                    "çº¸è´§è®°å½•æ•°": len(analysis.df_paper_net) if analysis.df_paper_net is not None else 0
                }
            }
            
            report_json = json.dumps(report_data, indent=2, default=str, ensure_ascii=False)
            st.download_button(
                label="ğŸ“„ ä¸‹è½½åˆ†ææŠ¥å‘Š",
                data=report_json.encode('utf-8'),
                file_name=f"hedge_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
        
        with col3:
            # å¯¼å‡ºæ‰€æœ‰æ•°æ®
            @st.cache_data
            def convert_to_excel(df_dict):
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    for sheet_name, df in df_dict.items():
                        if df is not None and not df.empty:
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                return output.getvalue()
            
            if analysis.df_relations is not None:
                excel_data = convert_to_excel({
                    "åŒ¹é…ç»“æœ": analysis.df_relations,
                    "å®è´§æ•°æ®": analysis.df_physical,
                    "çº¸è´§å‡€ä»“": analysis.df_paper_net
                })
                
                st.download_button(
                    label="ğŸ“Š ä¸‹è½½å®Œæ•´æ•°æ®",
                    data=excel_data,
                    file_name=f"hedge_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
    
    else:
        # æ¬¢è¿é¡µé¢
        if not (paper_file and physical_file):
            st.markdown("---")
            st.markdown('<div class="info-box">ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ çº¸è´§å’Œå®è´§æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ</div>', unsafe_allow_html=True)
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("""
                ### ğŸ¯ ç³»ç»Ÿå·¥ä½œæµç¨‹
                
                1. **æ•°æ®ä¸Šä¼ **
                   - çº¸è´§äº¤æ˜“æ•°æ® (åŒ…å«äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡ã€å•†å“ã€ä»·æ ¼ç­‰)
                   - å®è´§æŒä»“æ•°æ® (åŒ…å«Cargo_IDã€äº¤æ˜“é‡ã€å¥—ä¿ä»£ç†ã€ç›®æ ‡æœˆä»½ç­‰)
                
                2. **æ™ºèƒ½åŒ¹é…**
                   - FIFOå†…éƒ¨å¯¹å†²ï¼šå…ˆå¯¹çº¸è´§è¿›è¡Œå‡€é¢åŒ–
                   - å®è´§åŒ¹é…ï¼šåŸºäºå“ç§ã€æœˆä»½ã€æ—¶é—´çš„æ™ºèƒ½åŒ¹é…
                   - BRENTä¼˜å…ˆï¼šä¼˜å…ˆåŒ¹é…BRENTåŸºå‡†çš„äº¤æ˜“
                
                3. **æ·±åº¦åˆ†æ**
                   - åŒ¹é…ç‡ä¸è¦†ç›–ç‡åˆ†æ
                   - P/Lä¸MTMåˆ†æ
                   - æ—¶é—´å·®ä¸æ•ˆç‡åˆ†æ
                   - é£é™©æŒ‡æ ‡è®¡ç®— (VaRã€å¤æ™®æ¯”ç‡ç­‰)
                
                4. **æ•°æ®å¯¼å‡º**
                   - åŒ¹é…ç»“æœCSV
                   - åˆ†ææŠ¥å‘ŠJSON
                   - å®Œæ•´æ•°æ®Excel
                """)
            
            with col2:
                st.markdown("""
                ### ğŸ“‹ æ•°æ®è¦æ±‚
                
                **çº¸è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Trade Date`: äº¤æ˜“æ—¥æœŸ
                - `Volume`: äº¤æ˜“é‡ (æ­£ä¹°è´Ÿå–)
                - `Commodity`: å•†å“å“ç§
                - `Month`: åˆçº¦æœˆä»½ (å¯é€‰)
                - `Price`: äº¤æ˜“ä»·æ ¼ (å¯é€‰)
                
                **å®è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Cargo_ID`: å®è´§ç¼–å·
                - `Volume`: äº¤æ˜“é‡
                - `Hedge_Proxy`: å¥—ä¿ä»£ç†
                - `Target_Contract_Month`: ç›®æ ‡æœˆä»½
                - `Direction`: æ–¹å‘ (Buy/Sell)
                
                **å¯é€‰å­—æ®µ:**
                - `Designation_Date`: æŒ‡å®šæ—¥æœŸ
                - `Pricing_Benchmark`: å®šä»·åŸºå‡†
                - `Pricing_Start`: å®šä»·å¼€å§‹æ—¥æœŸ
                """)
            
            st.markdown("---")
            
            # ç¤ºä¾‹æ•°æ®å±•ç¤º
            with st.expander("ğŸ“š æŸ¥çœ‹æ•°æ®æ ¼å¼ç¤ºä¾‹"):
                example_tab1, example_tab2 = st.tabs(["çº¸è´§ç¤ºä¾‹", "å®è´§ç¤ºä¾‹"])
                
                with example_tab1:
                    example_paper = pd.DataFrame({
                        'Trade Date': ['2024-01-15', '2024-01-16', '2024-01-17'],
                        'Volume': [1000, -500, 2000],
                        'Commodity': ['BRENT', 'BRENT', 'JCC'],
                        'Month': ['JAN 25', 'JAN 25', 'FEB 25'],
                        'Price': [75.50, 76.20, 74.80],
                        'Recap No': ['TKT-001', 'TKT-002', 'TKT-003']
                    })
                    st.dataframe(example_paper, use_container_width=True)
                
                with example_tab2:
                    example_physical = pd.DataFrame({
                        'Cargo_ID': ['PHY-2025-001', 'PHY-2025-002', 'PHY-2025-003'],
                        'Volume': [500000, 300000, 400000],
                        'Hedge_Proxy': ['BRENT', 'JCC', 'BRENT'],
                        'Target_Contract_Month': ['JAN 25', 'FEB 25', 'JAN 25'],
                        'Direction': ['Buy', 'Buy', 'Sell'],
                        'Designation_Date': ['2024-01-10', '2024-01-15', '2024-01-20']
                    })
                    st.dataframe(example_physical, use_container_width=True)

if __name__ == "__main__":
    main()