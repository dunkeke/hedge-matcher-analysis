import streamlit as st
import pandas as pd
import numpy as np
import io
import time
import warnings
from datetime import datetime, timedelta
from collections import deque
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots  # æ·»åŠ è¿™è¡Œ
import re
import json

warnings.filterwarnings("ignore", category=UserWarning)

# ---------------------------------------------------------
# 1. æ ¸å¿ƒåŒ¹é…å¼•æ“ (å®Œæ•´é›†æˆ)
# ---------------------------------------------------------

class HedgeMatchingEngine:
    """å¥—ä¿åŒ¹é…å¼•æ“ - å®Œæ•´ç‰ˆ"""
    
    def __init__(self):
        self.df_paper = None
        self.df_physical = None
        self.df_paper_net = None
        self.df_relations = None
        self.df_physical_updated = None
        self.df_cargo_summary = None
        self.df_overall_summary = None
        self.df_cargo_month_summary = None
        self.df_cargo_close_summary = None
        
    def clean_str(self, series):
        """æ¸…æ´—å­—ç¬¦ä¸²"""
        return series.astype(str).str.strip().str.upper().replace('NAN', '')
    
    def standardize_month(self, series):
        """æ ‡å‡†åŒ–æœˆä»½æ ¼å¼"""
        s = series.astype(str).str.strip().str.upper()
        s = s.str.replace('-', ' ', regex=False).str.replace('/', ' ', regex=False)
        dates = pd.to_datetime(s, errors='coerce')
        result = dates.dt.strftime('%b %y').str.upper()
        mask_invalid = dates.isna()
        
        if mask_invalid.any():
            invalid = s[mask_invalid]
            def swap_if_match(val):
                m = re.match(r'^(\d{2})\s*([A-Z]{3})$', val)
                if m:
                    yr, mon = m.groups()
                    return f"{mon} {yr}"
                return val
            swapped = invalid.map(swap_if_match)
            swapped_dates = pd.to_datetime(swapped, errors='coerce')
            swapped_formatted = swapped_dates.dt.strftime('%b %y').str.upper()
            result.loc[mask_invalid & swapped_dates.notna()] = swapped_formatted.loc[swapped_dates.notna()]
            result.loc[mask_invalid & swapped_dates.isna()] = swapped.loc[swapped_dates.isna()]
        return result
    
    def calculate_net_positions(self, df_paper):
        """FIFOå‡€ä»“è®¡ç®—"""
        st.info("ğŸ”„ æ‰§è¡Œçº¸è´§å†…éƒ¨å¯¹å†² (FIFO Netting)...")
        progress_bar = st.progress(0)
        
        df_paper = df_paper.sort_values(by='Trade Date').reset_index(drop=True)
        df_paper['Group_Key'] = df_paper['Std_Commodity'] + "_" + df_paper['Month']
        records = df_paper.to_dict('records')
        groups = {}
        
        # åˆ†ç»„
        for i, row in enumerate(records):
            key = row['Group_Key']
            if key not in groups:
                groups[key] = []
            groups[key].append(i)
            if i % 100 == 0:
                progress_bar.progress(min(i / len(records) * 0.5, 0.5))
        
        # FIFOå‡€é¢åŒ–
        group_count = 0
        total_groups = len(groups)
        for key, indices in groups.items():
            open_queue = deque()
            for idx in indices:
                row = records[idx]
                current_vol = row.get('Volume', 0)
                records[idx]['Net_Open_Vol'] = current_vol
                records[idx]['Closed_Vol'] = 0
                records[idx]['Close_Events'] = []
                
                if abs(current_vol) < 0.0001:
                    continue
                
                current_sign = 1 if current_vol > 0 else -1
                
                # å°è¯•ä¸é˜Ÿåˆ—ä¸­çš„äº¤æ˜“æŠµæ¶ˆ
                while open_queue:
                    q_idx, q_vol, q_sign = open_queue[0]
                    if q_sign != current_sign:  # æ–¹å‘ç›¸åæ‰èƒ½æŠµæ¶ˆ
                        offset = min(abs(current_vol), abs(q_vol))
                        current_vol -= (current_sign * offset)
                        q_vol -= (q_sign * offset)
                        
                        # è®°å½•å¹³ä»“äº‹ä»¶
                        close_event = {
                            'Ref': str(records[idx].get('Recap No', '')),
                            'Date': records[idx].get('Trade Date'),
                            'Vol': offset,
                            'Price': records[idx].get('Price', 0)
                        }
                        records[q_idx]['Close_Events'].append(close_event)
                        records[q_idx]['Closed_Vol'] += offset
                        records[q_idx]['Net_Open_Vol'] = q_vol
                        records[idx]['Closed_Vol'] += offset
                        records[idx]['Net_Open_Vol'] = current_vol
                        
                        if abs(q_vol) < 0.0001:
                            open_queue.popleft()
                        else:
                            open_queue[0] = (q_idx, q_vol, q_sign)
                        
                        if abs(current_vol) < 0.0001:
                            break
                    else:
                        break
                
                # å‰©ä½™éƒ¨åˆ†å…¥é˜Ÿ
                if abs(current_vol) > 0.0001:
                    open_queue.append((idx, current_vol, current_sign))
            
            group_count += 1
            progress_bar.progress(0.5 + (group_count / total_groups) * 0.5)
        
        progress_bar.progress(1.0)
        st.success(f"âœ… çº¸è´§å†…éƒ¨å¯¹å†²å®Œæˆï¼å…±å¤„ç† {len(groups)} ä¸ªå•†å“-æœˆä»½ç»„åˆ")
        return pd.DataFrame(records)
    
    def match_hedges(self, df_physical, df_paper_net):
        """å®è´§åŒ¹é…"""
        st.info("ğŸ”„ å¼€å§‹å®è´§åŒ¹é…...")
        progress_bar = st.progress(0)
        
        hedge_relations = []
        default_match_start_date = pd.NaT
        trade_years = df_paper_net['Trade Date'].dropna().dt.year
        if not trade_years.empty:
            default_match_start_date = pd.Timestamp(year=int(trade_years.max()), month=11, day=13)

        active_paper = df_paper_net[df_paper_net['Net_Open_Vol'] > 0.0001].copy()
        if pd.notna(default_match_start_date):
            active_paper = active_paper[active_paper['Trade Date'] >= default_match_start_date]
        active_paper['Allocated_To_Phy'] = 0.0
        active_paper['_original_index'] = active_paper.index

        def filter_close_events(events, start_date):
            if pd.isna(start_date):
                return list(events or [])
            return [
                event for event in (events or [])
                if pd.notna(event.get('Date')) and event.get('Date') >= start_date
            ]

        close_event_pool = {}
        for _, ticket in active_paper.iterrows():
            events = ticket.get('Close_Events', []) or []
            if events:
                sorted_events = sorted(
                    events,
                    key=lambda x: x['Date'] if pd.notna(x.get('Date')) else pd.Timestamp.min
                )
                close_event_pool[ticket['_original_index']] = deque(
                    {
                        'remaining': float(e.get('Vol', 0)),
                        'price': e.get('Price', 0),
                        'date': e.get('Date')
                    }
                    for e in sorted_events
                    if abs(e.get('Vol', 0)) > 0.0001
                )
        
        df_phy = df_physical.copy()
        df_phy['_orig_idx'] = df_phy.index
        
        # BRENTä¼˜å…ˆåŒ¹é… + æŒ‡å®šè´§ç‰©ä¼˜å…ˆçº§
        priority_order = {
            'PHY-2026-004': 0,
            'PHY-2026-005': 1,
            'PHY-2026-001': 2,
            'PHY-2026-002': 3,
            'PHY-2026-003': 4,
        }
        if 'Pricing_Benchmark' in df_phy.columns:
            df_phy['_bench_priority'] = df_phy['Pricing_Benchmark'].astype(str).str.upper().str.contains('BRENT')
        else:
            df_phy['_bench_priority'] = False
        df_phy['_cargo_priority'] = df_phy['Cargo_ID'].astype(str).str.upper().map(priority_order).fillna(99)
        df_phy = df_phy.sort_values(
            by=['_bench_priority', '_cargo_priority', '_orig_idx'],
            ascending=[False, True, True]
        ).reset_index(drop=True)
        df_phy = df_phy.drop(columns=['_bench_priority', '_cargo_priority'])
        
        total_cargos = len(df_phy)
        
        for idx, (_, cargo) in enumerate(df_phy.iterrows()):
            cargo_id = cargo.get('Cargo_ID')
            phy_vol = cargo.get('Unhedged_Volume', 0)
            
            if abs(phy_vol) < 0.0001:
                continue
            
            proxy = str(cargo.get('Hedge_Proxy', ''))
            target_month = cargo.get('Target_Contract_Month', None)
            desig_date = cargo.get('Designation_Date', pd.NaT)
            cargo_start_date = default_match_start_date
            if pd.notna(desig_date):
                desig_start = desig_date.normalize()
                if pd.isna(cargo_start_date) or desig_start > cargo_start_date:
                    cargo_start_date = desig_start
            benchmark = str(cargo.get('Pricing_Benchmark', '')).upper()
            proxy_candidates = [proxy] if proxy else []
            if 'BRENT' in benchmark:
                proxy_candidates = proxy_candidates or []
                proxy_candidates.extend(['PHY-2026-001', 'PHY-2026-002', 'PHY-2026-003'])
                proxy_candidates = list(dict.fromkeys(proxy_candidates))
            
            for proxy_value in proxy_candidates:
                if abs(phy_vol) < 1:
                    break

                # ç­›é€‰å€™é€‰äº¤æ˜“
                mask = (
                    (active_paper['Std_Commodity'].str.contains(proxy_value, regex=False)) &
                    (active_paper['Month'] == target_month)
                )
                if pd.notna(cargo_start_date):
                    mask &= active_paper['Trade Date'] >= cargo_start_date
                candidates_df = active_paper[mask].copy()

                if candidates_df.empty:
                    continue

                # æ—¶é—´æ’åºï¼šæœ‰æŒ‡å®šæ—¥æœŸæŒ‰æ—¶é—´å·®ï¼Œå¦åˆ™FIFO
                if pd.notna(desig_date) and not candidates_df['Trade Date'].isnull().all():
                    candidates_df['Time_Lag_Days'] = (candidates_df['Trade Date'] - desig_date).dt.days
                    candidates_df['Abs_Lag'] = candidates_df['Time_Lag_Days'].abs()
                    candidates_df = candidates_df.sort_values(by=['Abs_Lag', 'Trade Date'])
                else:
                    candidates_df['Time_Lag_Days'] = np.nan
                    candidates_df = candidates_df.sort_values(by='Trade Date')

                # åˆ†é…åŒ¹é…
                for _, ticket in candidates_df.iterrows():
                    if abs(phy_vol) < 1:
                        break

                    original_index = ticket['_original_index']
                    curr_allocated = active_paper.at[original_index, 'Allocated_To_Phy']
                    curr_net_open = ticket.get('Net_Open_Vol', 0)
                    avail = curr_net_open - curr_allocated

                    if abs(avail) < 0.0001:
                        continue

                    alloc_amt = min(avail, phy_vol)
                    phy_vol -= alloc_amt
                    active_paper.at[original_index, 'Allocated_To_Phy'] += alloc_amt

                    # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
                    open_price = ticket.get('Price', 0)
                    mtm_price = ticket.get('Mtm Price', open_price)  # é»˜è®¤ä¸ºå¼€ä»“ä»·
                    total_pl_raw = ticket.get('Total P/L', 0)
                    close_events = ticket.get('Close_Events', [])

                    # æ ¼å¼åŒ–å¹³ä»“è·¯å¾„
                    close_path_str = ""
                    if close_events:
                        try:
                            sorted_events = sorted(
                                filter_close_events(close_events, cargo_start_date),
                                key=lambda x: x['Date'] if pd.notna(x['Date']) else pd.Timestamp.min
                            )
                            details = []
                            for e in sorted_events:
                                d_str = e['Date'].strftime('%Y-%m-%d') if pd.notna(e['Date']) else 'N/A'
                                p_str = f"@{e['Price']}" if pd.notna(e['Price']) else ""
                                details.append(f"[{d_str} Tkt#{e['Ref']} Vol:{e['Vol']:.0f} {p_str}]")
                            close_path_str = " -> ".join(details)
                        except:
                            close_path_str = str(close_events)

                    # è®¡ç®—åˆ†é…æ¯”ä¾‹
                    ratio = abs(alloc_amt) / abs(ticket.get('Volume', 0)) if abs(ticket.get('Volume', 0)) > 0 else 0
                    unrealized_mtm = (mtm_price - open_price) * alloc_amt
                    allocated_total_pl = total_pl_raw * ratio

                    close_volume = 0.0
                    close_price_total = 0.0
                    close_queue = close_event_pool.get(original_index, deque())
                    while close_queue and pd.notna(cargo_start_date):
                        peek = close_queue[0]
                        if pd.isna(peek.get('date')) or peek['date'] >= cargo_start_date:
                            break
                        close_queue.popleft()
                    remaining = abs(alloc_amt)
                    used_close_events = []
                    while remaining > 0 and close_queue:
                        event = close_queue[0]
                        take = min(remaining, event['remaining'])
                        close_volume += take
                        close_price_total += take * event['price']
                        used_close_events.append({
                            'Date': event.get('date'),
                            'Vol': take,
                            'Price': event.get('price')
                        })
                        event['remaining'] -= take
                        remaining -= take
                        if event['remaining'] < 0.0001:
                            close_queue.popleft()
                    close_event_pool[original_index] = close_queue
                    close_wap = (close_price_total / close_volume) if close_volume > 0 else 0

                    hedge_relations.append({
                        'Cargo_ID': cargo_id,
                        'Proxy': proxy_value,
                        'Designation_Date': desig_date,
                        'Open_Date': ticket.get('Trade Date'),
                        'Time_Lag': ticket.get('Time_Lag_Days'),
                        'Ticket_ID': ticket.get('Recap No'),
                        'Month': ticket.get('Month'),
                        'Allocated_Vol': alloc_amt,
                        'Trade_Volume': ticket.get('Volume', 0),
                        'Trade_Net_Open': ticket.get('Net_Open_Vol', 0),
                        'Trade_Closed_Vol': ticket.get('Closed_Vol', 0),
                        'Open_Price': open_price,
                        'MTM_Price': mtm_price,
                        'Alloc_Unrealized_MTM': round(unrealized_mtm, 2),
                        'Alloc_Total_PL': round(allocated_total_pl, 2),
                        'Close_Path_Details': close_path_str,
                        'Allocated_Close_Vol': close_volume,
                        'Close_WAP': close_wap,
                        'Allocated_Close_Events': used_close_events,
                    })

                    # æ›´æ–°å®è´§æœªå¯¹å†²é‡
                    orig_idx = cargo.get('_orig_idx')
                    if orig_idx in df_physical.index:
                        df_physical.at[orig_idx, 'Unhedged_Volume'] = phy_vol
            
            progress_bar.progress((idx + 1) / total_cargos)
        
        # æ›´æ–°åˆ†é…é‡
        cols_to_update = active_paper[['_original_index', 'Allocated_To_Phy']].set_index('_original_index')
        df_paper_net.update(cols_to_update)
        
        progress_bar.progress(1.0)
        df_relations = pd.DataFrame(hedge_relations)
        if not df_relations.empty:
            df_relations['Abs_Allocated_Vol'] = df_relations['Allocated_Vol'].abs()
            df_relations['Close_Value'] = df_relations['Allocated_Close_Vol'] * df_relations['Close_WAP']
            df_relations['Open_Value'] = df_relations['Abs_Allocated_Vol'] * df_relations['Open_Price']
            total_open_vol = df_relations['Abs_Allocated_Vol'].sum()
            total_close_vol = df_relations['Allocated_Close_Vol'].sum()
            total_open_wap = (
                df_relations['Open_Value'].sum() / total_open_vol
                if total_open_vol > 0 else 0
            )
            total_close_wap = (
                df_relations['Close_Value'].sum() / total_close_vol
                if total_close_vol > 0 else 0
            )
            self.df_overall_summary = pd.DataFrame([{
                'Matched_Open_Vol': total_open_vol,
                'Open_WAP': total_open_wap,
                'Matched_Close_Vol': total_close_vol,
                'Close_WAP': total_close_wap
            }])
            open_summary = df_relations.groupby('Cargo_ID').apply(
                lambda grp: pd.Series({
                    'Matched_Open_Vol': grp['Abs_Allocated_Vol'].sum(),
                    'Open_WAP': grp['Open_Value'].sum() / grp['Abs_Allocated_Vol'].sum()
                    if grp['Abs_Allocated_Vol'].sum() > 0 else 0,
                    'Matched_Close_Vol': grp['Allocated_Close_Vol'].sum(),
                    'Close_WAP': grp['Close_Value'].sum() / grp['Allocated_Close_Vol'].sum()
                    if grp['Allocated_Close_Vol'].sum() > 0 else 0
                })
            ).reset_index()
            self.df_cargo_month_summary = df_relations.groupby(['Cargo_ID', 'Month']).apply(
                lambda grp: pd.Series({
                    'Matched_Open_Vol': grp['Abs_Allocated_Vol'].sum(),
                    'Open_WAP': grp['Open_Value'].sum() / grp['Abs_Allocated_Vol'].sum()
                    if grp['Abs_Allocated_Vol'].sum() > 0 else 0
                })
            ).reset_index()
            close_summary = df_relations.explode('Allocated_Close_Events')
            if not close_summary.empty:
                close_summary[['Close_Date', 'Close_Vol', 'Close_Price']] = close_summary['Allocated_Close_Events'].apply(
                    lambda e: pd.Series({
                        'Close_Date': e.get('Date') if isinstance(e, dict) else pd.NaT,
                        'Close_Vol': e.get('Vol', 0) if isinstance(e, dict) else 0,
                        'Close_Price': e.get('Price', 0) if isinstance(e, dict) else 0,
                    })
                )
                close_summary = close_summary[close_summary['Close_Vol'] > 0]
                close_summary['Close_Value'] = close_summary['Close_Vol'] * close_summary['Close_Price']
                close_summary = close_summary.sort_values(by=['Cargo_ID', 'Close_Date'])
                self.df_cargo_close_summary = close_summary.groupby('Cargo_ID').apply(
                    lambda grp: pd.Series({
                        'Matched_Close_Vol': grp['Close_Vol'].sum(),
                        'Close_WAP': grp['Close_Value'].sum() / grp['Close_Vol'].sum()
                        if grp['Close_Vol'].sum() > 0 else 0,
                        'Close_Path': " -> ".join(
                            f"[{row.Close_Date.strftime('%Y-%m-%d') if pd.notna(row.Close_Date) else 'N/A'} "
                            f"V:{row.Close_Vol:.0f} @ {row.Close_Price}]"
                            for row in grp.itertuples()
                        )
                    })
                ).reset_index()
            else:
                self.df_cargo_close_summary = pd.DataFrame(
                    columns=['Cargo_ID', 'Matched_Close_Vol', 'Close_WAP', 'Close_Path']
                )
            df_physical = df_physical.merge(open_summary, on='Cargo_ID', how='left')
            df_physical['Post_1112_Open_Vol'] = df_physical['Matched_Open_Vol']
            df_physical['Post_1112_Open_WAP'] = df_physical['Open_WAP']
            df_physical['Post_1112_Close_Vol'] = df_physical['Matched_Close_Vol']
            df_physical['Post_1112_Close_WAP'] = df_physical['Close_WAP']
            self.df_cargo_summary = open_summary.copy()
            self.df_cargo_summary['Post_1112_Open_Vol'] = self.df_cargo_summary['Matched_Open_Vol']
            self.df_cargo_summary['Post_1112_Open_WAP'] = self.df_cargo_summary['Open_WAP']
            self.df_cargo_summary['Post_1112_Close_Vol'] = self.df_cargo_summary['Matched_Close_Vol']
            self.df_cargo_summary['Post_1112_Close_WAP'] = self.df_cargo_summary['Close_WAP']
        else:
            df_physical['Matched_Open_Vol'] = 0.0
            df_physical['Open_WAP'] = 0.0
            df_physical['Matched_Close_Vol'] = 0.0
            df_physical['Close_WAP'] = 0.0
            df_physical['Post_1112_Open_Vol'] = 0.0
            df_physical['Post_1112_Open_WAP'] = 0.0
            df_physical['Post_1112_Close_Vol'] = 0.0
            df_physical['Post_1112_Close_WAP'] = 0.0
            self.df_cargo_summary = pd.DataFrame(
                columns=[
                    'Cargo_ID',
                    'Matched_Open_Vol',
                    'Open_WAP',
                    'Matched_Close_Vol',
                    'Close_WAP',
                    'Post_1112_Open_Vol',
                    'Post_1112_Open_WAP',
                    'Post_1112_Close_Vol',
                    'Post_1112_Close_WAP'
                ]
            )
            self.df_cargo_month_summary = pd.DataFrame(
                columns=['Cargo_ID', 'Month', 'Matched_Open_Vol', 'Open_WAP']
            )
            self.df_cargo_close_summary = pd.DataFrame(
                columns=['Cargo_ID', 'Matched_Close_Vol', 'Close_WAP', 'Close_Path']
            )
            self.df_overall_summary = pd.DataFrame(
                columns=[
                    'Matched_Open_Vol',
                    'Open_WAP',
                    'Matched_Close_Vol',
                    'Close_WAP'
                ]
            )
        st.success(f"âœ… å®è´§åŒ¹é…å®Œæˆï¼å…±ç”Ÿæˆ {len(df_relations)} æ¡åŒ¹é…è®°å½•")
        
        return df_relations, df_physical
    
    def run_matching(self, df_paper_raw, df_physical_raw):
        """æ‰§è¡Œå®Œæ•´åŒ¹é…æµç¨‹"""
        # æ•°æ®é¢„å¤„ç†
        st.info("ğŸ”„ æ•°æ®é¢„å¤„ç†ä¸­...")
        
        # çº¸è´§é¢„å¤„ç†
        df_paper = df_paper_raw.copy()
        
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        required_cols_paper = ['Trade Date', 'Volume', 'Commodity']
        for col in required_cols_paper:
            if col not in df_paper.columns:
                st.error(f"çº¸è´§æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {col}")
                return None, None, None, None
        
        # æ ‡å‡†åŒ–å¤„ç†
        df_paper['Trade Date'] = pd.to_datetime(df_paper['Trade Date'], errors='coerce')
        df_paper['Volume'] = pd.to_numeric(df_paper['Volume'], errors='coerce').fillna(0)
        df_paper['Std_Commodity'] = self.clean_str(df_paper['Commodity'])
        
        if 'Month' in df_paper.columns:
            df_paper['Month'] = self.standardize_month(df_paper['Month'])
        else:
            # å¦‚æœæ²¡æœ‰Monthåˆ—ï¼Œå°è¯•ä»å…¶ä»–åˆ—æ¨æ–­æˆ–åˆ›å»ºé»˜è®¤å€¼
            df_paper['Month'] = df_paper['Trade Date'].dt.strftime('%b %y').str.upper()
        
        # å¤„ç†ç¼ºå¤±å­—æ®µ
        if 'Recap No' not in df_paper.columns:
            df_paper['Recap No'] = [f"TKT-{i+1:04d}" for i in range(len(df_paper))]
        
        for col in ['Price', 'Mtm Price', 'Total P/L']:
            if col not in df_paper.columns:
                df_paper[col] = 0.0
        
        # å®è´§é¢„å¤„ç†
        df_physical = df_physical_raw.copy()
        
        # æ ‡å‡†åŒ–åˆ—å
        col_mapping = {
            'Target_Pricing_Month': 'Target_Contract_Month',
            'Month': 'Target_Contract_Month',
            'Hedge_Proxy': 'Hedge_Proxy',
            'Direction': 'Direction'
        }
        
        for old_col, new_col in col_mapping.items():
            if old_col in df_physical.columns and new_col not in df_physical.columns:
                df_physical[new_col] = df_physical[old_col]
        
        # ç¡®ä¿å¿…è¦åˆ—
        if 'Volume' in df_physical.columns:
            df_physical['Volume'] = pd.to_numeric(df_physical['Volume'], errors='coerce').fillna(0)
            df_physical['Unhedged_Volume'] = df_physical['Volume']
        
        if 'Hedge_Proxy' in df_physical.columns:
            df_physical['Hedge_Proxy'] = self.clean_str(df_physical['Hedge_Proxy'])
        
        if 'Target_Contract_Month' in df_physical.columns:
            df_physical['Target_Contract_Month'] = self.standardize_month(df_physical['Target_Contract_Month'])
        
        # æŒ‡å®šæ—¥æœŸ
        date_cols = ['Designation_Date', 'Pricing_Start', 'Trade Date']
        for col in date_cols:
            if col in df_physical.columns:
                df_physical['Designation_Date'] = pd.to_datetime(df_physical[col], errors='coerce')
                break
        else:
            df_physical['Designation_Date'] = pd.NaT
        
        # æ‰§è¡ŒåŒ¹é…
        self.df_paper_net = self.calculate_net_positions(df_paper)
        self.df_relations, self.df_physical_updated = self.match_hedges(df_physical, self.df_paper_net)
        
        return self.df_relations, self.df_physical_updated, self.df_paper_net, df_paper

# ---------------------------------------------------------
# 2. åˆ†ææ¨¡å— (åŸºäºçœŸå®åŒ¹é…ç»“æœ)
# ---------------------------------------------------------

class HedgeAnalysis:
    """å¥—ä¿åˆ†ææ¨¡å—"""
    
    def __init__(self, df_relations, df_physical, df_paper_net):
        self.df_relations = df_relations
        self.df_physical = df_physical
        self.df_paper_net = df_paper_net
        self.summary_stats = {}
        self.calculate_summary()
    
    def calculate_summary(self):
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        if self.df_relations.empty:
            return
        
        try:
            # åŒ¹é…ç»Ÿè®¡
            total_matched = abs(self.df_relations['Allocated_Vol']).sum() if 'Allocated_Vol' in self.df_relations.columns else 0
            total_physical = abs(self.df_physical['Volume']).sum() if 'Volume' in self.df_physical.columns else 0
            match_rate = (total_matched / total_physical * 100) if total_physical > 0 else 0
            
            # è´¢åŠ¡ç»Ÿè®¡
            total_pl = self.df_relations['Alloc_Total_PL'].sum() if 'Alloc_Total_PL' in self.df_relations.columns else 0
            total_unrealized = self.df_relations['Alloc_Unrealized_MTM'].sum() if 'Alloc_Unrealized_MTM' in self.df_relations.columns else 0
            
            # æ•°é‡ç»Ÿè®¡
            matched_cargos = self.df_relations['Cargo_ID'].nunique() if 'Cargo_ID' in self.df_relations.columns else 0
            total_cargos = self.df_physical['Cargo_ID'].nunique() if 'Cargo_ID' in self.df_physical.columns else 0
            total_tickets = len(self.df_relations)
            
            # æ—¶é—´ç»Ÿè®¡
            if 'Time_Lag' in self.df_relations.columns:
                time_lag_abs = self.df_relations['Time_Lag'].abs()
                avg_time_lag = time_lag_abs.mean() if not time_lag_abs.isna().all() else 0
                std_time_lag = time_lag_abs.std() if not time_lag_abs.isna().all() else 0
            else:
                avg_time_lag = std_time_lag = 0
            
            self.summary_stats = {
                'total_matched': total_matched,
                'total_physical': total_physical,
                'match_rate': match_rate,
                'total_pl': total_pl,
                'total_unrealized': total_unrealized,
                'matched_cargos': matched_cargos,
                'total_cargos': total_cargos,
                'total_tickets': total_tickets,
                'avg_time_lag': avg_time_lag,
                'std_time_lag': std_time_lag
            }
        except Exception as e:
            st.warning(f"è®¡ç®—æ±‡æ€»ç»Ÿè®¡æ—¶å‡ºé”™: {e}")
            self.summary_stats = {
                'total_matched': 0,
                'total_physical': 0,
                'match_rate': 0,
                'total_pl': 0,
                'total_unrealized': 0,
                'matched_cargos': 0,
                'total_cargos': 0,
                'total_tickets': 0,
                'avg_time_lag': 0,
                'std_time_lag': 0
            }
    
    def create_summary_metrics(self):
        """åˆ›å»ºæ¦‚è§ˆæŒ‡æ ‡å¡ç‰‡"""
        stats = self.summary_stats
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“Š åŒ¹é…ç‡", f"{stats['match_rate']:.1f}%", 
                     delta=f"{stats['total_matched']:,.0f}/{stats['total_physical']:,.0f}")
        
        with col2:
            coverage = (stats['matched_cargos'] / stats['total_cargos'] * 100) if stats['total_cargos'] > 0 else 0
            st.metric("ğŸ“¦ åŒ¹é…è¦†ç›–ç‡", f"{coverage:.1f}%",
                     delta=f"{stats['matched_cargos']}/{stats['total_cargos']}")
        
        with col3:
            st.metric("ğŸ’° æ€»P/L", f"${stats['total_pl']:,.2f}",
                     delta=f"æœªå®ç°: ${stats['total_unrealized']:,.2f}")
        
        with col4:
            st.metric("â±ï¸ å¹³å‡æ—¶é—´å·®", f"{stats['avg_time_lag']:.1f}å¤©",
                     delta=f"Â±{stats['std_time_lag']:.1f}å¤©")
    
    def create_match_volume_chart(self):
        """åŒ¹é…é‡åˆ†å¸ƒå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Allocated_Vol' not in self.df_relations.columns:
                return None
            
            # æŒ‰Cargo_IDæ±‡æ€»
            cargo_summary = self.df_relations.copy()
            cargo_summary['Allocated_Vol_Abs'] = abs(cargo_summary['Allocated_Vol'])
            
            if 'Cargo_ID' not in cargo_summary.columns:
                return None
            
            cargo_group = cargo_summary.groupby('Cargo_ID')['Allocated_Vol_Abs'].sum().reset_index()
            
            # æŒ‰åŒ¹é…é‡æ’åºï¼Œå–å‰20
            top_cargos = cargo_group.sort_values('Allocated_Vol_Abs', ascending=False).head(20)
            
            fig = px.bar(top_cargos, 
                         x='Cargo_ID', y='Allocated_Vol_Abs',
                         title='ğŸ“ˆ å„Cargo_IDåŒ¹é…é‡TOP20',
                         labels={'Allocated_Vol_Abs': 'åŒ¹é…é‡', 'Cargo_ID': 'å®è´§ç¼–å·'},
                         color='Allocated_Vol_Abs',
                         color_continuous_scale='Viridis')
            fig.update_layout(xaxis_tickangle=-45)
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºåŒ¹é…é‡å›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_pl_analysis_chart(self):
        """P/Låˆ†æå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Alloc_Total_PL' not in self.df_relations.columns:
                return None
            
            # ä½¿ç”¨æ›´ç®€å•çš„å›¾è¡¨ï¼Œé¿å…å¤æ‚å­å›¾
            fig = px.histogram(self.df_relations, 
                              x='Alloc_Total_PL',
                              nbins=30,
                              title='ğŸ’° P/Låˆ†å¸ƒç›´æ–¹å›¾',
                              labels={'Alloc_Total_PL': 'P/Lå€¼'})
            fig.add_vline(x=0, line_dash="dash", line_color="red")
            
            # æ·»åŠ ç®±çº¿å›¾æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            fig2 = px.box(self.df_relations, 
                         y='Alloc_Total_PL',
                         title='ğŸ“Š P/Lç»Ÿè®¡ç®±çº¿å›¾')
            
            return fig, fig2
        except Exception as e:
            st.warning(f"åˆ›å»ºP/Lå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None, None
    
    def create_simple_pl_chart(self):
        """ç®€åŒ–çš„P/Lå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Alloc_Total_PL' not in self.df_relations.columns:
                return None
            
            fig = go.Figure()
            
            # æ·»åŠ ç›´æ–¹å›¾
            fig.add_trace(go.Histogram(
                x=self.df_relations['Alloc_Total_PL'],
                nbinsx=30,
                name='P/Låˆ†å¸ƒ',
                marker_color='skyblue'
            ))
            
            # æ·»åŠ é›¶çº¿
            fig.add_vline(x=0, line_dash="dash", line_color="red")
            
            fig.update_layout(
                title='ğŸ’° P/Låˆ†å¸ƒåˆ†æ',
                xaxis_title='P/Lå€¼',
                yaxis_title='é¢‘æ•°',
                showlegend=False
            )
            
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºç®€åŒ–P/Lå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_time_analysis_chart(self):
        """æ—¶é—´åˆ†æå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Time_Lag' not in self.df_relations.columns:
                return None
            
            time_lag_data = self.df_relations['Time_Lag'].dropna()
            if time_lag_data.empty:
                return None
            
            fig = px.histogram(time_lag_data,
                             nbinsx=30,
                             title='â±ï¸ æ—¶é—´å·®åˆ†å¸ƒ',
                             labels={'value': 'æ—¶é—´å·®(å¤©)'})
            fig.add_vline(x=0, line_dash="dash", line_color="green",
                         annotation_text="å®Œç¾åŒ¹é…")
            
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºæ—¶é—´åˆ†æå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_price_analysis_chart(self):
        """ä»·æ ¼åˆ†æå›¾è¡¨"""
        try:
            if self.df_relations.empty:
                return None
            
            required_cols = ['Open_Price', 'MTM_Price', 'Allocated_Vol']
            missing_cols = [col for col in required_cols if col not in self.df_relations.columns]
            
            if missing_cols:
                st.info(f"ç¼ºå°‘ä»·æ ¼åˆ†ææ‰€éœ€åˆ—: {missing_cols}")
                return None
            
            fig = px.scatter(self.df_relations, 
                            x='Open_Price', 
                            y='MTM_Price',
                            size=abs(self.df_relations['Allocated_Vol']),
                            color='Alloc_Total_PL' if 'Alloc_Total_PL' in self.df_relations.columns else None,
                            title='ğŸ’¹ å¼€ä»“ä»· vs å½“å‰ä»·åˆ†æ',
                            labels={'Open_Price': 'å¼€ä»“ä»·', 'MTM_Price': 'å½“å‰ä»·'},
                            hover_data=['Cargo_ID', 'Ticket_ID', 'Allocated_Vol'] if 'Cargo_ID' in self.df_relations.columns else [])
            
            # æ·»åŠ å¹³ä»·çº¿
            min_price = min(self.df_relations['Open_Price'].min(), self.df_relations['MTM_Price'].min())
            max_price = max(self.df_relations['Open_Price'].max(), self.df_relations['MTM_Price'].max())
            
            fig.add_trace(go.Scatter(x=[min_price, max_price],
                                    y=[min_price, max_price],
                                    mode='lines',
                                    name='å¹³ä»·çº¿',
                                    line=dict(color='red', dash='dash')))
            
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºä»·æ ¼åˆ†æå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_month_distribution_chart(self):
        """æœˆä»½åˆ†å¸ƒå›¾è¡¨"""
        try:
            if self.df_relations.empty or 'Month' not in self.df_relations.columns:
                return None
            
            month_summary = self.df_relations.copy()
            month_summary['Allocated_Vol_Abs'] = abs(month_summary['Allocated_Vol'])
            month_group = month_summary.groupby('Month')['Allocated_Vol_Abs'].sum().reset_index()
            
            fig = px.bar(month_group.sort_values('Allocated_Vol_Abs', ascending=False),
                         x='Month', y='Allocated_Vol_Abs',
                         title='ğŸ“… å„æœˆä»½åŒ¹é…é‡åˆ†å¸ƒ',
                         labels={'Allocated_Vol_Abs': 'åŒ¹é…é‡', 'Month': 'åˆçº¦æœˆä»½'},
                         color='Allocated_Vol_Abs',
                         color_continuous_scale='Plasma')
            fig.update_layout(xaxis_tickangle=-45)
            
            return fig
        except Exception as e:
            st.warning(f"åˆ›å»ºæœˆä»½åˆ†å¸ƒå›¾è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def create_match_detail_table(self, max_rows=50):
        """åˆ›å»ºåŒ¹é…æ˜ç»†è¡¨"""
        try:
            if self.df_relations.empty:
                return pd.DataFrame()
            
            # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
            display_cols = []
            possible_cols = ['Cargo_ID', 'Ticket_ID', 'Month', 'Allocated_Vol',
                            'Open_Price', 'MTM_Price', 'Alloc_Total_PL',
                            'Alloc_Unrealized_MTM', 'Time_Lag', 'Proxy']
            
            for col in possible_cols:
                if col in self.df_relations.columns:
                    display_cols.append(col)
            
            if not display_cols:
                return pd.DataFrame()
            
            # æ ¼å¼åŒ–æ•°å­—
            formatted_df = self.df_relations[display_cols].copy()
            
            # æ•°å­—æ ¼å¼åŒ–å‡½æ•°
            def format_number(x):
                if isinstance(x, (int, float, np.integer, np.floating)):
                    return f"{x:,.2f}"
                return x
            
            # æ ¼å¼åŒ–æ•°å€¼åˆ—
            num_cols = ['Allocated_Vol', 'Open_Price', 'MTM_Price', 
                       'Alloc_Total_PL', 'Alloc_Unrealized_MTM']
            for col in num_cols:
                if col in formatted_df.columns:
                    formatted_df[col] = formatted_df[col].apply(format_number)
            
            return formatted_df.head(max_rows)
        except Exception as e:
            st.warning(f"åˆ›å»ºåŒ¹é…æ˜ç»†è¡¨æ—¶å‡ºé”™: {e}")
            return pd.DataFrame()
    
    def create_risk_metrics(self):
        """é£é™©æŒ‡æ ‡è®¡ç®—"""
        try:
            if self.df_relations.empty or 'Alloc_Total_PL' not in self.df_relations.columns:
                return {}
            
            risk_metrics = {}
            pl_series = self.df_relations['Alloc_Total_PL']
            
            # VaRè®¡ç®— (95%ç½®ä¿¡æ°´å¹³)
            if len(pl_series) > 1:
                var_95 = np.percentile(pl_series, 5)  # 95% VaR
                cvar_95 = pl_series[pl_series <= var_95].mean() if len(pl_series[pl_series <= var_95]) > 0 else 0
                risk_metrics['VaR_95'] = var_95
                risk_metrics['CVaR_95'] = cvar_95
                risk_metrics['PL_StdDev'] = pl_series.std()
                risk_metrics['PL_Max'] = pl_series.max()
                risk_metrics['PL_Min'] = pl_series.min()
                
                # å¤æ™®æ¯”ç‡ (å‡è®¾æ— é£é™©åˆ©ç‡ä¸º0)
                avg_pl = pl_series.mean()
                std_pl = pl_series.std()
                risk_metrics['Sharpe_Ratio'] = avg_pl / std_pl if std_pl != 0 else 0
                
                # æœ€å¤§å›æ’¤
                pl_cumulative = pl_series.cumsum()
                running_max = pl_cumulative.expanding().max()
                drawdown = (pl_cumulative - running_max) / running_max * 100
                risk_metrics['Max_Drawdown'] = drawdown.min() if not drawdown.empty else 0
            
            return risk_metrics
        except Exception as e:
            st.warning(f"è®¡ç®—é£é™©æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            return {}

# ---------------------------------------------------------
# 3. Streamlit ä¸»åº”ç”¨
# ---------------------------------------------------------

def main():
    st.set_page_config(
        page_title="å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #374151;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        border-bottom: 2px solid #E5E7EB;
        padding-bottom: 0.5rem;
    }
    .success-box {
        background-color: #D1FAE5;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #10B981;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #DBEAFE;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3B82F6;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #FEF3C7;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #F59E0B;
        margin: 1rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ“ˆ å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    st.markdown("### ä¸“ä¸šå¥—ä¿åŒ¹é…ä¸é£é™©åˆ†æå·¥å…· | åŸºäºçœŸå®åŒ¹é…æ•°æ®")
    
    # åˆå§‹åŒ–session state
    if 'engine' not in st.session_state:
        st.session_state.engine = HedgeMatchingEngine()
    if 'analysis' not in st.session_state:
        st.session_state.analysis = None
    if 'matching_complete' not in st.session_state:
        st.session_state.matching_complete = False
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.markdown("### ğŸ“ æ•°æ®ä¸Šä¼ ")
        
        paper_file = st.file_uploader(
            "çº¸è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="paper_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Trade Date, Volume, Commodityç­‰å­—æ®µ"
        )
        
        physical_file = st.file_uploader(
            "å®è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="physical_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Cargo_ID, Volume, Hedge_Proxyç­‰å­—æ®µ"
        )
        
        st.markdown("---")
        st.markdown("### âš™ï¸ åˆ†æè®¾ç½®")
        
        show_charts = st.checkbox("æ˜¾ç¤ºåˆ†æå›¾è¡¨", value=True)
        show_risk = st.checkbox("æ˜¾ç¤ºé£é™©æŒ‡æ ‡", value=True)
        max_rows = st.slider("è¡¨æ ¼æ˜¾ç¤ºè¡Œæ•°", 10, 200, 50)
        
        st.markdown("---")
        
        if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰æ•°æ®", type="secondary"):
            st.session_state.engine = HedgeMatchingEngine()
            st.session_state.analysis = None
            st.session_state.matching_complete = False
            st.rerun()
    
    # ä¸»å†…å®¹åŒº
    if paper_file is not None and physical_file is not None:
        # è¯»å–æ•°æ®
        try:
            # è¯»å–çº¸è´§æ•°æ®
            if paper_file.name.endswith(('.xlsx', '.xls')):
                df_paper_raw = pd.read_excel(paper_file)
            else:
                df_paper_raw = pd.read_csv(paper_file)
            
            # è¯»å–å®è´§æ•°æ®
            if physical_file.name.endswith(('.xlsx', '.xls')):
                df_physical_raw = pd.read_excel(physical_file)
            else:
                df_physical_raw = pd.read_csv(physical_file)
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            with st.expander("ğŸ“‹ åŸå§‹æ•°æ®é¢„è§ˆ", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**çº¸è´§æ•°æ®** ({len(df_paper_raw)}è¡Œ, {len(df_paper_raw.columns)}åˆ—)")
                    st.dataframe(df_paper_raw.head(10), use_container_width=True)
                    st.caption(f"å­—æ®µ: {', '.join(df_paper_raw.columns.tolist()[:8])}...")
                
                with col2:
                    st.markdown(f"**å®è´§æ•°æ®** ({len(df_physical_raw)}è¡Œ, {len(df_physical_raw.columns)}åˆ—)")
                    st.dataframe(df_physical_raw.head(10), use_container_width=True)
                    st.caption(f"å­—æ®µ: {', '.join(df_physical_raw.columns.tolist()[:8])}...")
            
            # æ‰§è¡ŒåŒ¹é…æŒ‰é’®
            if st.button("ğŸš€ æ‰§è¡Œå¥—ä¿åŒ¹é…", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨æ‰§è¡Œå¥—ä¿åŒ¹é…ï¼Œè¯·ç¨å€™..."):
                    try:
                        # æ‰§è¡ŒåŒ¹é…
                        df_relations, df_physical_updated, df_paper_net, df_paper_processed = st.session_state.engine.run_matching(
                            df_paper_raw, df_physical_raw
                        )
                        
                        if df_relations is not None and not df_relations.empty:
                            # åˆ›å»ºåˆ†ææ¨¡å—
                            st.session_state.analysis = HedgeAnalysis(
                                df_relations, df_physical_updated, df_paper_net
                            )
                            st.session_state.matching_complete = True
                            
                            # æ˜¾ç¤ºåŒ¹é…æˆåŠŸä¿¡æ¯
                            st.markdown('<div class="success-box">âœ… å¥—ä¿åŒ¹é…æˆåŠŸå®Œæˆï¼</div>', unsafe_allow_html=True)
                            
                            # æ˜¾ç¤ºåŒ¹é…è¿‡ç¨‹æ•°æ®
                            with st.expander("ğŸ“Š åŒ¹é…è¿‡ç¨‹æ•°æ®", expanded=False):
                                tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(
                                    ["çº¸è´§å‡€ä»“", "å®è´§æ›´æ–°", "åŒ¹é…å…³ç³»", "å®è´§æ±‡æ€»", "æ€»ä½“æ±‡æ€»", "å¼€ä»“æŒ‰æœˆæ±‡æ€»", "å¹³ä»“æ±‡æ€»"]
                                )
                                
                                with tab1:
                                    if df_paper_net is not None:
                                        st.dataframe(df_paper_net.head(20), use_container_width=True)
                                        st.caption(f"çº¸è´§å‡€ä»“æ•°æ® ({len(df_paper_net)}è¡Œ)")
                                    else:
                                        st.info("æ— çº¸è´§å‡€ä»“æ•°æ®")
                                
                                with tab2:
                                    if df_physical_updated is not None:
                                        st.dataframe(df_physical_updated.head(20), use_container_width=True)
                                        st.caption(f"æ›´æ–°åå®è´§æ•°æ® ({len(df_physical_updated)}è¡Œ)")
                                    else:
                                        st.info("æ— å®è´§æ›´æ–°æ•°æ®")
                                
                                with tab3:
                                    if df_relations is not None:
                                        st.dataframe(df_relations.head(20), use_container_width=True)
                                        st.caption(f"åŒ¹é…å…³ç³»æ•°æ® ({len(df_relations)}è¡Œ)")
                                    else:
                                        st.info("æ— åŒ¹é…å…³ç³»æ•°æ®")

                                with tab4:
                                    summary_df = st.session_state.engine.df_cargo_summary
                                    if summary_df is not None and not summary_df.empty:
                                        phy_2026 = summary_df[
                                            summary_df['Cargo_ID'].astype(str).str.upper().str.startswith('PHY-2026')
                                        ]
                                        st.dataframe(phy_2026, use_container_width=True)
                                        st.caption(f"å®è´§æ±‡æ€»æ•°æ® ({len(phy_2026)}è¡Œ)")
                                    else:
                                        st.info("æ— å®è´§æ±‡æ€»æ•°æ®")

                                with tab5:
                                    overall_df = st.session_state.engine.df_overall_summary
                                    if overall_df is not None and not overall_df.empty:
                                        st.dataframe(overall_df, use_container_width=True)
                                        st.caption("æ‰€æœ‰åŒ¹é…å¼€ä»“/å¹³ä»“åŠ æƒå‡ä»·æ±‡æ€»")
                                    else:
                                        st.info("æ— æ€»ä½“æ±‡æ€»æ•°æ®")

                                with tab6:
                                    month_df = st.session_state.engine.df_cargo_month_summary
                                    if month_df is not None and not month_df.empty:
                                        month_2026 = month_df[
                                            month_df['Cargo_ID'].astype(str).str.upper().str.startswith('PHY-2026')
                                        ]
                                        st.dataframe(month_2026, use_container_width=True)
                                        st.caption(f"å¼€ä»“æŒ‰æœˆæ±‡æ€» ({len(month_2026)}è¡Œ)")
                                    else:
                                        st.info("æ— å¼€ä»“æŒ‰æœˆæ±‡æ€»æ•°æ®")

                                with tab7:
                                    close_df = st.session_state.engine.df_cargo_close_summary
                                    if close_df is not None and not close_df.empty:
                                        close_2026 = close_df[
                                            close_df['Cargo_ID'].astype(str).str.upper().str.startswith('PHY-2026')
                                        ]
                                        st.dataframe(close_2026, use_container_width=True)
                                        st.caption(f"å¹³ä»“æ±‡æ€» ({len(close_2026)}è¡Œ)")
                                    else:
                                        st.info("æ— å¹³ä»“æ±‡æ€»æ•°æ®")
                        else:
                            st.markdown('<div class="warning-box">âš ï¸ åŒ¹é…å®Œæˆä½†æœªç”ŸæˆåŒ¹é…è®°å½•ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼å’Œå†…å®¹</div>', unsafe_allow_html=True)
                            
                    except Exception as e:
                        st.error(f"åŒ¹é…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                        st.exception(e)
        
        except Exception as e:
            st.error(f"æ•°æ®è¯»å–é”™è¯¯: {str(e)}")
            st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå¹¶åŒ…å«å¿…è¦çš„å­—æ®µã€‚")
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.matching_complete and st.session_state.analysis is not None:
        st.markdown("---")
        st.markdown('<h2 class="sub-header">ğŸ“Š åŒ¹é…åˆ†æç»“æœ</h2>', unsafe_allow_html=True)
        
        analysis = st.session_state.analysis
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…æ•°æ®
        if analysis.df_relations.empty:
            st.warning("âš ï¸ åŒ¹é…ç»“æœä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return
        
        # 1. æ¦‚è§ˆæŒ‡æ ‡
        analysis.create_summary_metrics()
        
        # 2. åŒ¹é…æ˜ç»†è¡¨
        st.markdown('<h3 class="sub-header">ğŸ“‹ åŒ¹é…æ˜ç»†è¡¨</h3>', unsafe_allow_html=True)
        detailed_table = analysis.create_match_detail_table(max_rows)
        
        if not detailed_table.empty:
            st.dataframe(detailed_table, use_container_width=True)
            st.caption(f"æ˜¾ç¤ºå‰ {len(detailed_table)} æ¡è®°å½•ï¼Œå…± {len(analysis.df_relations)} æ¡åŒ¹é…è®°å½•")
        else:
            st.info("æ— åŒ¹é…æ˜ç»†æ•°æ®å¯æ˜¾ç¤º")
        
        # 3. åˆ†æå›¾è¡¨
        if show_charts and not analysis.df_relations.empty:
            st.markdown('<h3 class="sub-header">ğŸ“ˆ å¯è§†åŒ–åˆ†æ</h3>', unsafe_allow_html=True)
            
            # å›¾è¡¨é€‰é¡¹å¡
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ğŸ“Š åŒ¹é…é‡åˆ†æ", "ğŸ’° P/Låˆ†æ", 
                "â±ï¸ æ—¶é—´åˆ†æ", "ğŸ’¹ ä»·æ ¼åˆ†æ", "ğŸ“… æœˆä»½åˆ†å¸ƒ"
            ])
            
            with tab1:
                fig1 = analysis.create_match_volume_chart()
                if fig1:
                    st.plotly_chart(fig1, use_container_width=True)
                else:
                    st.info("æ— åŒ¹é…é‡æ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
            
            with tab2:
                fig2 = analysis.create_simple_pl_chart()
                if fig2:
                    st.plotly_chart(fig2, use_container_width=True)
                    
                    # æ˜¾ç¤ºP/Lç»Ÿè®¡æ•°æ®
                    if 'Alloc_Total_PL' in analysis.df_relations.columns:
                        pl_stats = analysis.df_relations['Alloc_Total_PL'].describe()
                        st.dataframe(pl_stats, use_container_width=True)
                else:
                    st.info("æ— P/Læ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
            
            with tab3:
                fig3 = analysis.create_time_analysis_chart()
                if fig3:
                    st.plotly_chart(fig3, use_container_width=True)
                    
                    # æ˜¾ç¤ºæ—¶é—´å·®ç»Ÿè®¡æ•°æ®
                    if 'Time_Lag' in analysis.df_relations.columns:
                        time_stats = analysis.df_relations['Time_Lag'].describe()
                        st.dataframe(time_stats, use_container_width=True)
                else:
                    st.info("æ— æ—¶é—´å·®æ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
            
            with tab4:
                fig4 = analysis.create_price_analysis_chart()
                if fig4:
                    st.plotly_chart(fig4, use_container_width=True)
                    
                    # æ˜¾ç¤ºä»·æ ¼ç»Ÿè®¡æ•°æ®
                    if 'Open_Price' in analysis.df_relations.columns and 'MTM_Price' in analysis.df_relations.columns:
                        price_stats = pd.DataFrame({
                            'Open_Price': analysis.df_relations['Open_Price'].describe(),
                            'MTM_Price': analysis.df_relations['MTM_Price'].describe()
                        }).T
                        st.dataframe(price_stats, use_container_width=True)
                else:
                    st.info("æ— ä»·æ ¼æ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
            
            with tab5:
                fig5 = analysis.create_month_distribution_chart()
                if fig5:
                    st.plotly_chart(fig5, use_container_width=True)
                    
                    # æ˜¾ç¤ºæœˆä»½ç»Ÿè®¡æ•°æ®
                    if 'Month' in analysis.df_relations.columns:
                        month_stats = analysis.df_relations['Month'].value_counts()
                        st.dataframe(month_stats, use_container_width=True)
                else:
                    st.info("æ— æœˆä»½æ•°æ®å¯ç”¨äºå›¾è¡¨åˆ†æ")
        
        # 4. é£é™©æŒ‡æ ‡
        if show_risk and not analysis.df_relations.empty:
            st.markdown('<h3 class="sub-header">âš ï¸ é£é™©æŒ‡æ ‡åˆ†æ</h3>', unsafe_allow_html=True)
            
            risk_metrics = analysis.create_risk_metrics()
            
            if risk_metrics:
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("VaR (95%)", f"${risk_metrics.get('VaR_95', 0):,.2f}")
                
                with col2:
                    st.metric("CVaR (95%)", f"${risk_metrics.get('CVaR_95', 0):,.2f}")
                
                with col3:
                    st.metric("å¤æ™®æ¯”ç‡", f"{risk_metrics.get('Sharpe_Ratio', 0):.2f}")
                
                with col4:
                    st.metric("æœ€å¤§å›æ’¤", f"{risk_metrics.get('Max_Drawdown', 0):.1f}%")
                
                # è¯¦ç»†é£é™©æŒ‡æ ‡è¡¨æ ¼
                with st.expander("æŸ¥çœ‹è¯¦ç»†é£é™©æŒ‡æ ‡"):
                    risk_df = pd.DataFrame.from_dict(risk_metrics, orient='index', columns=['å€¼'])
                    st.dataframe(risk_df.style.format("{:,.2f}"), use_container_width=True)
            else:
                st.info("æ— æ³•è®¡ç®—é£é™©æŒ‡æ ‡ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ•°æ®")
        
        # 5. æ•°æ®å¯¼å‡º
        st.markdown("---")
        st.markdown('<h3 class="sub-header">ğŸ’¾ æ•°æ®å¯¼å‡º</h3>', unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # å¯¼å‡ºåŒ¹é…ç»“æœ
            if not analysis.df_relations.empty:
                csv_data = analysis.df_relations.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åŒ¹é…ç»“æœ",
                    data=csv_data,
                    file_name=f"hedge_matching_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        with col2:
            # å¯¼å‡ºåˆ†ææŠ¥å‘Š
            report_data = {
                "åŒ¹é…ç»Ÿè®¡": analysis.summary_stats,
                "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "æ•°æ®é‡": {
                    "åŒ¹é…è®°å½•æ•°": len(analysis.df_relations),
                    "å®è´§è®°å½•æ•°": len(analysis.df_physical),
                    "çº¸è´§è®°å½•æ•°": len(analysis.df_paper_net) if analysis.df_paper_net is not None else 0
                }
            }
            
            report_json = json.dumps(report_data, indent=2, default=str, ensure_ascii=False)
            st.download_button(
                label="ğŸ“„ ä¸‹è½½åˆ†ææŠ¥å‘Š",
                data=report_json.encode('utf-8'),
                file_name=f"hedge_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
        
        with col3:
            # å¯¼å‡ºæ‰€æœ‰æ•°æ®
            @st.cache_data
            def convert_to_excel(df_dict):
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    for sheet_name, df in df_dict.items():
                        if df is not None and not df.empty:
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                return output.getvalue()
            
            if analysis.df_relations is not None:
                excel_data = convert_to_excel({
                    "åŒ¹é…ç»“æœ": analysis.df_relations,
                    "å®è´§æ•°æ®": analysis.df_physical,
                    "çº¸è´§å‡€ä»“": analysis.df_paper_net
                })
                
                st.download_button(
                    label="ğŸ“Š ä¸‹è½½å®Œæ•´æ•°æ®",
                    data=excel_data,
                    file_name=f"hedge_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
    
    else:
        # æ¬¢è¿é¡µé¢
        if not (paper_file and physical_file):
            st.markdown("---")
            st.markdown('<div class="info-box">ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ çº¸è´§å’Œå®è´§æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ</div>', unsafe_allow_html=True)
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("""
                ### ğŸ¯ ç³»ç»Ÿå·¥ä½œæµç¨‹
                
                1. **æ•°æ®ä¸Šä¼ **
                   - çº¸è´§äº¤æ˜“æ•°æ® (åŒ…å«äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡ã€å•†å“ã€ä»·æ ¼ç­‰)
                   - å®è´§æŒä»“æ•°æ® (åŒ…å«Cargo_IDã€äº¤æ˜“é‡ã€å¥—ä¿ä»£ç†ã€ç›®æ ‡æœˆä»½ç­‰)
                
                2. **æ™ºèƒ½åŒ¹é…**
                   - FIFOå†…éƒ¨å¯¹å†²ï¼šå…ˆå¯¹çº¸è´§è¿›è¡Œå‡€é¢åŒ–
                   - å®è´§åŒ¹é…ï¼šåŸºäºå“ç§ã€æœˆä»½ã€æ—¶é—´çš„æ™ºèƒ½åŒ¹é…
                   - BRENTä¼˜å…ˆï¼šä¼˜å…ˆåŒ¹é…BRENTåŸºå‡†çš„äº¤æ˜“
                
                3. **æ·±åº¦åˆ†æ**
                   - åŒ¹é…ç‡ä¸è¦†ç›–ç‡åˆ†æ
                   - P/Lä¸MTMåˆ†æ
                   - æ—¶é—´å·®ä¸æ•ˆç‡åˆ†æ
                   - é£é™©æŒ‡æ ‡è®¡ç®— (VaRã€å¤æ™®æ¯”ç‡ç­‰)
                
                4. **æ•°æ®å¯¼å‡º**
                   - åŒ¹é…ç»“æœCSV
                   - åˆ†ææŠ¥å‘ŠJSON
                   - å®Œæ•´æ•°æ®Excel
                """)
            
            with col2:
                st.markdown("""
                ### ğŸ“‹ æ•°æ®è¦æ±‚
                
                **çº¸è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Trade Date`: äº¤æ˜“æ—¥æœŸ
                - `Volume`: äº¤æ˜“é‡ (æ­£ä¹°è´Ÿå–)
                - `Commodity`: å•†å“å“ç§
                
                **å®è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Cargo_ID`: å®è´§ç¼–å·
                - `Volume`: äº¤æ˜“é‡
                - `Hedge_Proxy`: å¥—ä¿ä»£ç†
                
                **å¯é€‰å­—æ®µ:**
                - `Month`: åˆçº¦æœˆä»½
                - `Price`: äº¤æ˜“ä»·æ ¼
                - `Target_Contract_Month`: ç›®æ ‡æœˆä»½
                - `Designation_Date`: æŒ‡å®šæ—¥æœŸ
                """)

if __name__ == "__main__":
    main()
